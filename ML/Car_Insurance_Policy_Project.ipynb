{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W7FMz57bINqY"
      },
      "source": [
        "### Dataset Description\n",
        "\n",
        "Customer ID - A unique identifier for the customer\n",
        "Shopping Point - Unique identifier for the shopping point of the customer\n",
        "Record Type - The record type (0: shopping point, 1: purchase point)\n",
        "Day - Day of the week when the shopping point was created\n",
        "Time - Time of the day when the shopping point was created\n",
        "State - The state where the shopping point was created\n",
        "Location Coordinate - The location where the shopping point was created\n",
        "Group Size - The size of the group the customer is shopping for\n",
        "Homeowner - Whether the customer is a homeowner or not\n",
        "Car Age - The age of the customer's car\n",
        "Car Value - Value of the customer's car at purchase time\n",
        "Risk Factor - The risk factor assigned to the customer\n",
        "Age Oldest - Age of the oldest person in the customer's group\n",
        "Age Youngest - Age of the youngest person in the customer's group\n",
        "Married Couple - Indicates whether the group includes a married couple\n",
        "C Previous - Previous Car Type\n",
        "Duration Previous - The duration of the customer's previous insurance policy\n",
        "A - Coverage level\n",
        "B Smoking type\n",
        "C - Car type\n",
        "D - Purpose of the vehicle\n",
        "E - Safety features\n",
        "F - Driver's historic record\n",
        "G - Area where the user will drive the car (rural, urban, suburban or hazardous)     \n",
        "Cost - The cost of the insurance policy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I84CGzPqIj89"
      },
      "source": [
        "## Code\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Install required packages\n",
        "!pip install scikit-learn numpy pandas psycopg2-binary SQLAlchemy bokeh matplotlib seaborn plotly joblib cloudpickle snowflake-connector-python snowflake-sqlalchemy\n",
        "\n",
        "from snowflake.connector.pandas_tools import write_pandas\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import snowflake.connector\n",
        "import configparser\n",
        "from sqlalchemy import create_engine\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler, MinMaxScaler, LabelEncoder\n",
        "from datetime import datetime, timedelta\n",
        "from sklearn.feature_selection import SelectFromModel\n",
        "from sklearn.cluster import KMeans, MiniBatchKMeans\n",
        "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.svm import SVR\n",
        "from sklearn.neighbors import KNeighborsRegressor\n",
        "from sklearn.neural_network import MLPRegressor\n",
        "from scipy.stats import mode\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import plotly\n",
        "import plotly.express as px\n",
        "import plotly.graph_objects as go\n",
        "from plotly.subplots import make_subplots\n",
        "from bokeh.plotting import figure, output_file, show, output_notebook\n",
        "from bokeh.models import HoverTool, ColumnDataSource\n",
        "import joblib\n",
        "import cloudpickle\n",
        "import warnings\n",
        "import sklearn\n",
        "import sqlalchemy\n",
        "import matplotlib\n",
        "\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Function to check package versions\n",
        "def check_versions():\n",
        "    versions = {}\n",
        "    versions['pandas'] = pd.__version__\n",
        "    versions['numpy'] = np.__version__\n",
        "    versions['sqlalchemy'] = sqlalchemy.__version__\n",
        "    versions['sklearn'] = sklearn.__version__\n",
        "    versions['datetime'] = datetime.now().isoformat()\n",
        "    versions['scipy'] = mode.__module__\n",
        "    versions['matplotlib'] = matplotlib.__version__\n",
        "    versions['seaborn'] = sns.__version__\n",
        "    versions['plotly'] = plotly.__version__\n",
        "    versions['bokeh'] = 'Version info not directly accessible'\n",
        "    versions['joblib'] = joblib.__version__\n",
        "    versions['cloudpickle'] = cloudpickle.__version__\n",
        "\n",
        "    return versions\n",
        "\n",
        "# Print versions\n",
        "versions = check_versions()\n",
        "for package, version in versions.items():\n",
        "    print(f\"{package}: {version}\")\n",
        "\n",
        "# Additional detailed info for sklearn submodules\n",
        "sklearn_submodules = {\n",
        "    'model_selection': train_test_split.__module__,\n",
        "    'preprocessing.StandardScaler': StandardScaler.__module__,\n",
        "    'preprocessing.MinMaxScaler': MinMaxScaler.__module__,\n",
        "    'preprocessing.LabelEncoder': LabelEncoder.__module__,\n",
        "    'feature_selection.SelectFromModel': SelectFromModel.__module__,\n",
        "    'cluster.KMeans': KMeans.__module__,\n",
        "    'cluster.MiniBatchKMeans': MiniBatchKMeans.__module__,\n",
        "    'ensemble.RandomForestRegressor': RandomForestRegressor.__module__,\n",
        "    'tree.DecisionTreeRegressor': DecisionTreeRegressor.__module__,\n",
        "    'linear_model.LinearRegression': LinearRegression.__module__,\n",
        "    'svm.SVR': SVR.__module__,\n",
        "    'neighbors.KNeighborsRegressor': KNeighborsRegressor.__module__,\n",
        "    'neural_network.MLPRegressor': MLPRegressor.__module__,\n",
        "    'ensemble.GradientBoostingRegressor': GradientBoostingRegressor.__module__,\n",
        "    'metrics.mean_squared_error': mean_squared_error.__module__,\n",
        "    'metrics.mean_absolute_error': mean_absolute_error.__module__,\n",
        "    'metrics.r2_score': r2_score.__module__,\n",
        "}\n",
        "\n",
        "print(\"\\nsklearn submodules:\")\n",
        "for submodule, version in sklearn_submodules.items():\n",
        "    print(f\"{submodule}: {version}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bCGo7t_6gc_i"
      },
      "outputs": [],
      "source": [
        "# import pandas as pd\n",
        "# import numpy as np\n",
        "# from sqlalchemy import create_engine\n",
        "# from sklearn.model_selection import train_test_split\n",
        "# from sklearn.preprocessing import StandardScaler\n",
        "# from datetime import datetime, timedelta\n",
        "# from sklearn.feature_selection import SelectFromModel\n",
        "# from sklearn.preprocessing import MinMaxScaler, LabelEncoder\n",
        "# from sklearn.cluster import KMeans\n",
        "# from sklearn.cluster import MiniBatchKMeans\n",
        "# from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "# from sklearn.ensemble import RandomForestRegressor\n",
        "# from sklearn.tree import DecisionTreeRegressor\n",
        "# from sklearn.linear_model import LinearRegression\n",
        "# from sklearn.svm import SVR\n",
        "# from sklearn.neighbors import KNeighborsRegressor\n",
        "# from sklearn.neural_network import MLPRegressor\n",
        "# from sklearn.ensemble import GradientBoostingRegressor\n",
        "# from scipy.stats import mode\n",
        "# from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
        "# import matplotlib.pyplot as plt\n",
        "# import seaborn as sns\n",
        "# import plotly.express as px\n",
        "# import plotly.graph_objects as go\n",
        "# from plotly.subplots import make_subplots\n",
        "# from bokeh.plotting import figure, output_file, show, output_notebook\n",
        "# from bokeh.models import HoverTool, ColumnDataSource\n",
        "# import joblib\n",
        "# import warnings\n",
        "# warnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G2eelhl-K3um"
      },
      "outputs": [],
      "source": [
        "import psycopg2\n",
        "import configparser\n",
        "from sqlalchemy import create_engine\n",
        "import pandas as pd\n",
        "\n",
        "# Load database configuration from config file\n",
        "config = configparser.ConfigParser()\n",
        "config.read('db_config.ini')\n",
        "\n",
        "host = config['database']['DB_HOST']\n",
        "port = config['database'].getint('DB_PORT')\n",
        "user = config['database']['DB_USER']\n",
        "password = config['database']['DB_PASSWORD']\n",
        "database = config['database']['DB_NAME']\n",
        "\n",
        "# Create connection string\n",
        "connection_string = f'postgresql://{user}:{password}@{host}:{port}/{database}'\n",
        "\n",
        "# Connect to PostgreSQL\n",
        "try:\n",
        "    connection = psycopg2.connect(\n",
        "        host=host,\n",
        "        port=port,\n",
        "        user=user,\n",
        "        password=password,\n",
        "        database=database\n",
        "    )\n",
        "\n",
        "    cursor = connection.cursor()\n",
        "\n",
        "    # Execute SQL query\n",
        "    query = 'SELECT * FROM insurance_policy_data'\n",
        "    cursor.execute(query)\n",
        "    \n",
        "\n",
        "    # Fetch all rows into a list of tuples\n",
        "    rows = cursor.fetchall()\n",
        "\n",
        "    # Convert the fetched data into a Pandas DataFrame\n",
        "    columns = [desc[0] for desc in cursor.description]  # Get column names\n",
        "    df1 = pd.DataFrame(rows, columns=columns)\n",
        "\n",
        "    print(\"Data loaded successfully into DataFrame:\")\n",
        "\n",
        "except psycopg2.Error as e:\n",
        "    print(f\"Error connecting to PostgreSQL: {e}\")\n",
        "\n",
        "finally:\n",
        "    if connection:\n",
        "        cursor.close()\n",
        "        connection.close()\n",
        "        print(\"PostgreSQL connection is closed\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 193
        },
        "id": "dYL78MT5g2Sa",
        "outputId": "2f26be2c-143c-4b29-d493-a4c05738ac8f"
      },
      "outputs": [],
      "source": [
        "df1.head(3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FhzQ5rrTeCI4",
        "outputId": "7a550f3d-4e6c-4dd3-cbef-11de5e01551f"
      },
      "outputs": [],
      "source": [
        "df1.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AaFlPktrMskJ",
        "outputId": "004fc186-cb03-48ec-f8a1-1af0210fd371"
      },
      "outputs": [],
      "source": [
        "df1.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 739
        },
        "id": "wMgW980qKNFN",
        "outputId": "779dae96-3398-4000-ad77-29bc38c8c648"
      },
      "outputs": [],
      "source": [
        "df1.describe().transpose()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lZd7ayw7g5uS",
        "outputId": "829048d3-8f75-4050-ea63-0f8b36f50499"
      },
      "outputs": [],
      "source": [
        "duplicates_count = df1.duplicated().sum()\n",
        "\n",
        "if duplicates_count > 0:\n",
        "  print('Number of duplicate rows:', duplicates_count)\n",
        "  print('Dropping duplicate rows...')\n",
        "  df1 = df1.drop_duplicates()\n",
        "  duplicates_count = df1.duplicated().sum()\n",
        "print('Number of duplicate rows:', duplicates_count)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 868
        },
        "id": "Txy_gdJYQvAh",
        "outputId": "ef684fb7-61b4-4868-f057-d31450dbbf12"
      },
      "outputs": [],
      "source": [
        "def calculate_missing_values(df1):\n",
        "  missing_val = df1.isnull().sum()\n",
        "  missing_val_percent = 100 * df1.isnull().sum() / len(df1)\n",
        "  missing_values_table = pd.concat([missing_val, missing_val_percent], axis=1)\n",
        "  print (\"The dataframe has\", str(df1.shape[1]), \"columns and\", str(df1.shape[0]), \"Rows.\\n\")\n",
        "  missing_values_table = missing_values_table.rename(columns = {0 : 'Missing Values ', 1 : '% of Total Values'})\n",
        "  return missing_values_table\n",
        "\n",
        "calculate_missing_values(df1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 829
        },
        "id": "ZLubsoagjJ2l",
        "outputId": "86d34d2a-c4eb-4483-bde1-be4fc0f991d1"
      },
      "outputs": [],
      "source": [
        "# Set the figure size\n",
        "plt.figure(figsize=(10, 8))\n",
        "\n",
        "# Use Seaborn to create a heatmap of missing values\n",
        "sns.heatmap(df1.isnull(), cbar=False, cmap='viridis')\n",
        "\n",
        "# Set the title and labels\n",
        "plt.title('Heatmap of Missing Values')\n",
        "plt.xlabel('Columns')\n",
        "plt.ylabel('Rows')\n",
        "\n",
        "# Show the plot\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IzLkGndPRWk3",
        "outputId": "f7240f30-a3e4-4285-a99e-845613445a69"
      },
      "outputs": [],
      "source": [
        "def unique_values_with_counts(df1):\n",
        "  for column in df1.columns:\n",
        "    unique_vals = df1[column].value_counts()\n",
        "    if len(unique_vals) <= 40:\n",
        "      print(f\"Column: {column}\")\n",
        "      print(unique_vals)\n",
        "      print()\n",
        "\n",
        "unique_values_with_counts(df1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vXAHrJ0LCNO7"
      },
      "source": [
        "## State codes and names"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OBK8XyBIr50q"
      },
      "source": [
        "state             state_name\n",
        "\n",
        "0     FL                Florida\n",
        "\n",
        "1     NY              New York\n",
        "\n",
        "2     PA           Pennsylvania\n",
        "\n",
        "3     OH                 Ohio\n",
        "\n",
        "4     MD              Maryland\n",
        "\n",
        "5     IN              Indiana\n",
        "\n",
        "6     WA           Washington\n",
        "\n",
        "7     CO              Colorado\n",
        "\n",
        "8     AL              Alabama\n",
        "\n",
        "9     CT         Connecticut\n",
        "\n",
        "10    TN           Tennessee\n",
        "\n",
        "11    KY            Kentucky\n",
        "\n",
        "12    NV              Nevada\n",
        "\n",
        "13    MO             Missouri\n",
        "\n",
        "14    OR              Oregon\n",
        "\n",
        "15    UT                Utah\n",
        "\n",
        "16    OK            Oklahoma\n",
        "\n",
        "17    MS          Mississippi\n",
        "\n",
        "18    AR             Arkansas\n",
        "\n",
        "19    WI           Wisconsin\n",
        "\n",
        "20    GA              Georgia\n",
        "\n",
        "21    NH      New Hampshire\n",
        "\n",
        "22    NM          New Mexico\n",
        "\n",
        "23    ME               Maine\n",
        "\n",
        "24    ID                Idaho\n",
        "\n",
        "25    RI       Rhode Island\n",
        "\n",
        "26    KS             Kansas\n",
        "\n",
        "27    WV       West Virginia\n",
        "\n",
        "28    IA                 Iowa\n",
        "\n",
        "29    DE           Delaware\n",
        "\n",
        "30    DC  District of Columbia\n",
        "\n",
        "31    MT            Montana\n",
        "\n",
        "32    NE           Nebraska\n",
        "\n",
        "33    ND      North Dakota\n",
        "\n",
        "34    WY            Wyoming\n",
        "\n",
        "35    SD      South Dakota"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jIyUv2XoxqYA",
        "outputId": "36808b58-8d1c-4d87-b345-895ceec5d547"
      },
      "outputs": [],
      "source": [
        "num_unique_customers = df1['customer_id'].nunique()\n",
        "print(f\"Number of unique customer IDs: {num_unique_customers}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zrSGFFG5qzhS"
      },
      "source": [
        "## Handling Missing Values\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7vQMVcDV3SKk"
      },
      "outputs": [],
      "source": [
        "def fill_missing_and_replace_zero(df, columns, group_col='customer_id', replace_zero_columns=None):\n",
        "    \"\"\"\n",
        "    Fills missing values in specified columns based on the mode of the grouped values.\n",
        "    Replaces 0 values in specified columns with the mode of the grouped values.\n",
        "\n",
        "    Parameters:\n",
        "    df (pd.DataFrame): DataFrame containing the data.\n",
        "    columns (list): List of columns to fill missing values.\n",
        "    group_col (str): Column name to group by.\n",
        "    replace_zero_columns (list): List of columns to replace 0 values.\n",
        "\n",
        "    Returns:\n",
        "    pd.DataFrame: DataFrame with missing values and zero values handled.\n",
        "    \"\"\"\n",
        "    for column in columns:\n",
        "        df[column] = df.groupby(group_col)[column].transform(lambda x: x.fillna(x.mode()[0] if not x.mode().empty else x))\n",
        "        # Special case for columns that should have 0 as default value if no mode is found\n",
        "        if column in ['c_previous', 'duration_previous']:\n",
        "            df[column].fillna(0, inplace=True)\n",
        "\n",
        "    if replace_zero_columns:\n",
        "        for column in replace_zero_columns:\n",
        "            df[column] = df.groupby(group_col)[column].transform(lambda x: x.replace(0, x.mode()[0] if not x.mode().empty else x))\n",
        "\n",
        "    return df\n",
        "\n",
        "# Define the columns to fill missing values\n",
        "columns_to_fill = [\n",
        "    'state_code', 'location_coord', 'group_size', 'homeowner', 'car_age', 'car_value',\n",
        "    'risk_factor', 'age_oldest', 'age_youngest', 'married_couple', 'c_previous',\n",
        "    'duration_previous', 'A', 'B', 'C', 'D', 'E', 'F', 'G'\n",
        "]\n",
        "\n",
        "# Define columns to replace 0 values\n",
        "columns_to_replace_zero = ['state_code']\n",
        "\n",
        "# Fill missing values and replace zeros\n",
        "df1 = fill_missing_and_replace_zero(df1, columns_to_fill, replace_zero_columns=columns_to_replace_zero)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FH-Ay7tFIOPV",
        "outputId": "0bb216f2-23a7-4661-8cc2-bceb1fc1054d"
      },
      "outputs": [],
      "source": [
        "df1.isnull().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PsYZGu25DPRf"
      },
      "outputs": [],
      "source": [
        "# Drop rows where 'shopping_pt' is null\n",
        "df1.dropna(subset=['shopping_pt'], inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WTkCZH3Dhc_s"
      },
      "outputs": [],
      "source": [
        "# Sort the DataFrame by 'customer_id' and 'shopping_pt'\n",
        "df1.sort_values(['customer_id', 'shopping_pt'], inplace=True)\n",
        "\n",
        "# Group by 'customer_id' and apply cumcount(), which counts the number of occurrences within each group,\n",
        "# starting from 0 and adding 1 to start from 1 instead of 0\n",
        "df1['shopping_pt'] = df1.groupby('customer_id').cumcount() + 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nEMU7ZFOhliI"
      },
      "outputs": [],
      "source": [
        "# Function to handle missing record_type values according to specified rules\n",
        "def fill_missing_record_type(group):\n",
        "    # Ensure group is sorted by 'shopping_pt'\n",
        "    group = group.sort_values('shopping_pt').reset_index(drop=True)\n",
        "\n",
        "    # Handle the last row separately\n",
        "    if pd.isnull(group['record_type'].iloc[-1]):\n",
        "        group['record_type'].iloc[-1] = 1\n",
        "\n",
        "    # Handle the rest of the rows\n",
        "    for i in range(len(group) - 1):\n",
        "        if pd.isnull(group['record_type'].iloc[i]):\n",
        "            group['record_type'].iloc[i] = 0\n",
        "\n",
        "    return group\n",
        "\n",
        "# Apply the function to each group of 'customer_id'\n",
        "df1 = df1.groupby('customer_id', group_keys=False).apply(fill_missing_record_type)\n",
        "\n",
        "# Reset index\n",
        "df1.reset_index(drop=True, inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jXD6pbbNDoc3"
      },
      "outputs": [],
      "source": [
        "def fill_missing_days(df1):\n",
        "  # Forward fill missing values within each customer group\n",
        "  df1['day'] = df1.groupby('customer_id')['day'].ffill()\n",
        "\n",
        "  # Backward fill missing values within each customer group\n",
        "  df1['day'] = df1.groupby('customer_id')['day'].bfill()\n",
        "\n",
        "  # Handling edge cases of leading/trailing NaNs and isolated middle NaNs with different adjacent days\n",
        "  for customer in df1['customer_id'].unique():\n",
        "    customer_data = df1[df1['customer_id'] == customer]\n",
        "\n",
        "    for i in range(1, len(customer_data) - 1):\n",
        "      if pd.isnull(customer_data.iloc[i]['day']):\n",
        "        prev_day = customer_data.iloc[i - 1]['day']\n",
        "        next_day = customer_data.iloc[i + 1]['day']\n",
        "        if prev_day != next_day:\n",
        "          # Fill with the most frequent day within the customer's data\n",
        "          most_frequent_day = customer_data['day'].mode().iloc[0]\n",
        "          df1.loc[customer_data.index[i], 'day'] = most_frequent_day\n",
        "\n",
        "  return df1\n",
        "\n",
        "df1 = fill_missing_days(df1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-QHkzeSzDqWw"
      },
      "outputs": [],
      "source": [
        "# Convert 'time' to datetime for easier manipulation\n",
        "df1['time'] = pd.to_datetime(df1['time'], format='%H:%M:%S', errors='coerce')\n",
        "\n",
        "# Sort dataframe by 'customer_id' and 'shopping_pt' for sequential processing\n",
        "df1 = df1.sort_values(by=['customer_id', 'shopping_pt'])\n",
        "\n",
        "# Function to handle missing time values according to specified rules\n",
        "def fill_missing_times(group):\n",
        "    # Ensure group is sorted by 'shopping_pt'\n",
        "    group = group.sort_values('shopping_pt')\n",
        "\n",
        "    n = len(group)\n",
        "\n",
        "    # Handle first row\n",
        "    if pd.isnull(group['time'].iloc[0]):\n",
        "        if n > 1:\n",
        "            group['time'].iloc[0] = group['time'].iloc[1] - pd.Timedelta(minutes=2)\n",
        "        else:\n",
        "            group['time'].iloc[0] = pd.Timestamp(group['day'].iloc[0]) + pd.Timedelta(hours=15, minutes=0, seconds=0)\n",
        "\n",
        "    # Handle middle rows\n",
        "    for i in range(1, n-1):\n",
        "        if pd.isnull(group['time'].iloc[i]):\n",
        "            if group['day'].iloc[i] == group['day'].iloc[i-1]:\n",
        "                group['time'].iloc[i] = group['time'].iloc[i-1] + pd.Timedelta(minutes=2)\n",
        "            elif group['day'].iloc[i] == group['day'].iloc[i+1]:\n",
        "                group['time'].iloc[i] = group['time'].iloc[i+1] - pd.Timedelta(minutes=2)\n",
        "\n",
        "    # Handle last row if more than one row exists\n",
        "    if n > 1 and pd.isnull(group['time'].iloc[-1]):\n",
        "        if group['day'].iloc[-1] == group['day'].iloc[-2]:\n",
        "            group['time'].iloc[-1] = group['time'].iloc[-2] + pd.Timedelta(minutes=2)\n",
        "        else:\n",
        "            group['time'].iloc[-1] = pd.Timestamp(group['day'].iloc[-1]) + pd.Timedelta(hours=15, minutes=0, seconds=0)\n",
        "\n",
        "    return group\n",
        "\n",
        "# Apply the function to each group of 'customer_id'\n",
        "df1 = df1.groupby('customer_id', group_keys=False).apply(fill_missing_times)\n",
        "\n",
        "# Convert 'time' back to string format\n",
        "df1['time'] = df1['time'].dt.strftime('%H:%M:%S')\n",
        "\n",
        "# Reset index\n",
        "df1.reset_index(drop=True, inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1KjJauguTMjP",
        "outputId": "61771810-116a-4685-9c44-223d98ea52f0"
      },
      "outputs": [],
      "source": [
        "df1.isnull().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DXeyWibSobSC"
      },
      "outputs": [],
      "source": [
        "# Drop rows with NaN values in all columns except 'risk_factor'\n",
        "df1 = df1.dropna(subset=[col for col in df1.columns if col != 'risk_factor'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VJEakiT8ogXp",
        "outputId": "d2708004-88a2-4618-86d2-4021e64fd8e3"
      },
      "outputs": [],
      "source": [
        "df1.isnull().sum()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6R5k-a8KqsnU"
      },
      "source": [
        "## EDA"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tE6XJ8SloNk4"
      },
      "source": [
        "### Univariate Analysis"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5LQ7e-SIpfq_"
      },
      "source": [
        "#### Bar Plots and Histograms"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 562
        },
        "id": "ZP2PoM6s1Sy-",
        "outputId": "8fb6743a-ab04-45ce-b636-6e65d565c9eb"
      },
      "outputs": [],
      "source": [
        "shopping_counts = df1['shopping_pt'].value_counts().reset_index()\n",
        "\n",
        "# Rename columns to match expected by Plotly Express\n",
        "shopping_counts.columns = ['Shopping Points', 'Count']\n",
        "\n",
        "# Create a figure using Plotly Express\n",
        "fig = px.bar(shopping_counts, x='Shopping Points', y='Count',\n",
        "             labels={'Shopping Points': 'Shopping Points', 'Count': 'Count'},\n",
        "             title='Distribution of shopping_pt')\n",
        "\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 562
        },
        "id": "MEAXwHDq5GXa",
        "outputId": "de652905-2c3c-4c2f-fbdb-c81d14c02358"
      },
      "outputs": [],
      "source": [
        "day_counts = df1['day'].value_counts().reset_index()\n",
        "\n",
        "# Rename columns to match expected by Plotly Express\n",
        "day_counts.columns = ['Day', 'Count']\n",
        "\n",
        "# Create a figure using Plotly Express\n",
        "fig = px.bar(day_counts, x='Day', y='Count',\n",
        "             labels={'Day': 'Day', 'Count': 'Count'},\n",
        "             title='Distribution of day')\n",
        "\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 542
        },
        "id": "uR9L3lDu4jYp",
        "outputId": "b6550b6b-8c23-43d7-f9a1-9eb761c1999b"
      },
      "outputs": [],
      "source": [
        "state_counts = df1['state_code'].value_counts().reset_index()\n",
        "\n",
        "# Rename columns to match expected by Plotly Express\n",
        "state_counts.columns = ['State', 'Count']\n",
        "\n",
        "# Create a figure using Plotly Express\n",
        "fig = px.bar(state_counts, x='State', y='Count',\n",
        "             labels={'State': 'State', 'Count': 'Count'},\n",
        "             title='Distribution of state')\n",
        "\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 542
        },
        "id": "cyudGw5j8noX",
        "outputId": "bc3d4501-bb9c-47e9-c67e-668570d53375"
      },
      "outputs": [],
      "source": [
        "group_size_counts = df1['group_size'].value_counts().reset_index()\n",
        "\n",
        "# Rename columns to match expected by Plotly Express\n",
        "group_size_counts.columns = ['Group Size', 'Count']\n",
        "\n",
        "# Create a figure using Plotly Express\n",
        "fig = px.bar(group_size_counts, x='Group Size', y='Count',\n",
        "             labels={'Group Size': 'Group Size', 'Count': 'Count'},\n",
        "             title='Distribution of group_size')\n",
        "\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 542
        },
        "id": "cIkHb0vT-gic",
        "outputId": "06182ce6-1721-4262-8e0a-3c0549bbc00f"
      },
      "outputs": [],
      "source": [
        "fig = px.histogram(df1, x=df1['car_age'], nbins=10, title=f'Distribution of car_age')\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 562
        },
        "id": "NOO0kqLbHGvp",
        "outputId": "500eb190-54c2-4580-f826-ba6f20eaff14"
      },
      "outputs": [],
      "source": [
        "state_counts = df1['car_value'].value_counts().reset_index()\n",
        "\n",
        "# Rename columns to match expected by Plotly Express\n",
        "state_counts.columns = ['Car Value', 'Count']\n",
        "\n",
        "# Create a figure using Plotly Express\n",
        "fig = px.bar(state_counts, x='Car Value', y='Count',\n",
        "             labels={'State': 'Car Value', 'Count': 'Count'},\n",
        "             title='Distribution of Car Value')\n",
        "\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 562
        },
        "id": "MVYwUjtjCBLe",
        "outputId": "190fc6e7-e9b7-40c6-b16c-e217ba670533"
      },
      "outputs": [],
      "source": [
        "fig = px.histogram(df1, x=df1['age_oldest'], nbins=10, title=f'Distribution of age_oldest')\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 562
        },
        "id": "POMzjRSQC3az",
        "outputId": "2edae2d4-9613-4d76-edeb-e781f944d7d7"
      },
      "outputs": [],
      "source": [
        "fig = px.histogram(df1, x=df1['age_youngest'], nbins=10, title=f'Distribution of age_youngest')\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 562
        },
        "id": "PSiru98HEL-V",
        "outputId": "f7964ba4-aca6-4e23-de97-0a595b63736b"
      },
      "outputs": [],
      "source": [
        "C_previous_counts = df1['c_previous'].value_counts().reset_index()\n",
        "\n",
        "# Rename columns to match expected by Plotly Express\n",
        "C_previous_counts.columns = ['C previous', 'Count']\n",
        "\n",
        "# Create a figure using Plotly Express\n",
        "fig = px.bar(C_previous_counts, x='C previous', y='Count',\n",
        "             labels={'C previous': 'C previous', 'Count': 'Count'},\n",
        "             title='Distribution of c_previous')\n",
        "\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 562
        },
        "id": "LQ6e0RjhEzCE",
        "outputId": "8c4acfca-db67-4b76-af48-e8c57549fed5"
      },
      "outputs": [],
      "source": [
        "duration_previous_counts = df1['duration_previous'].value_counts().reset_index()\n",
        "\n",
        "# Rename columns to match expected by Plotly Express\n",
        "duration_previous_counts.columns = ['Duration Previous', 'Count']\n",
        "\n",
        "# Create a figure using Plotly Express\n",
        "fig = px.bar(duration_previous_counts, x='Duration Previous', y='Count',\n",
        "             labels={'Duration Previous': 'Duration Previous', 'Count': 'Count'},\n",
        "             title='Distribution of duration_previous')\n",
        "\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d7gD1JOxG-2G"
      },
      "source": [
        "#### Pie CHart"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 562
        },
        "id": "anzojkjzHWZ2",
        "outputId": "f794f36b-87ca-4487-81b1-598a6aaff072"
      },
      "outputs": [],
      "source": [
        "fig = px.pie(df1, names='group_size', title='Group Size Distribution')\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 562
        },
        "id": "dejZt3b7HAQa",
        "outputId": "664160c8-fa46-48e0-da8d-0309cacb2fa6"
      },
      "outputs": [],
      "source": [
        "fig = px.pie(df1, names='homeowner', title='Homeowner Status Distribution')\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 562
        },
        "id": "CZpVzRtwHcrJ",
        "outputId": "800ef697-dab2-449a-b034-9cda4d81b473"
      },
      "outputs": [],
      "source": [
        "fig = px.pie(df1, names='married_couple', title='Homeowner Status Distribution')\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2DkeXyraoaT5"
      },
      "source": [
        "### Bivariate Analysis"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z9XE_AkFq_gf"
      },
      "source": [
        "#### Scatter Plot"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 617
        },
        "id": "Q3rNSq0iodih",
        "outputId": "8705eb2c-6391-40ae-a5c2-4ead68f1ecbc"
      },
      "outputs": [],
      "source": [
        "# Prepare data\n",
        "source = ColumnDataSource(data=dict(\n",
        "    car_age=df1['car_age'],\n",
        "    cost=df1['cost'],\n",
        "    state_code=df1['state_code'],\n",
        "    homeowner=df1['homeowner']\n",
        "))\n",
        "\n",
        "# Configure Bokeh output\n",
        "output_file(\"scatter_plot.html\")  # For saving the output to an HTML file\n",
        "output_notebook()  # For displaying the output in a Jupyter Notebook\n",
        "\n",
        "# Create scatter plot with hover tool\n",
        "hover = HoverTool(tooltips=[\n",
        "    (\"Car Age\", \"@car_age\"),\n",
        "    (\"Insurance Cost\", \"@cost\"),\n",
        "    (\"State Code\", \"@state_code\"),\n",
        "    (\"Homeowner\", \"@homeowner\")\n",
        "])\n",
        "\n",
        "p = figure(width=800, height=600, tools=[hover], title=\"Interactive Scatter Plot\")\n",
        "p.circle('car_age', 'cost', size=10, source=source)\n",
        "\n",
        "show(p)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l9obR4y4rGMI"
      },
      "source": [
        "#### Box Plot"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MClDViH3qOa1",
        "outputId": "db047051-f2a7-43e7-933b-048923e3ed23"
      },
      "outputs": [],
      "source": [
        "# Create box plot with dropdown for state_code vs. cost\n",
        "fig = px.box(df1, x='state_code', y='cost', title='State Code vs. Insurance Cost',\n",
        "             labels={'state_code': 'State Code', 'cost': 'Insurance Cost'})\n",
        "\n",
        "fig.update_layout(xaxis={'categoryorder': 'total ascending'})\n",
        "\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6NWfsYgbHR8O",
        "outputId": "0d7ff136-4545-4bfc-889b-b1d385c57f17"
      },
      "outputs": [],
      "source": [
        "# Create box plot with dropdown for state_code vs. cost\n",
        "fig = px.box(df1, x='car_age', y='cost', title='Car Age vs. Insurance Cost',\n",
        "             labels={'car_age': 'Car Age', 'cost': 'Insurance Cost'})\n",
        "\n",
        "fig.update_layout(xaxis={'categoryorder': 'total ascending'})\n",
        "\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C0LsnkCerHQN"
      },
      "source": [
        "#### Pairplot with Tooltips"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "q9uPeGFDqgv-",
        "outputId": "48f8f60e-c277-4cef-a34e-80204c6a6f99"
      },
      "outputs": [],
      "source": [
        "# Create pairplot using seaborn\n",
        "sns.set(style=\"ticks\")\n",
        "sns_plot = sns.pairplot(df1[['car_age', 'cost', 'homeowner']], diag_kind='kde')\n",
        "\n",
        "# Convert seaborn pairplot to Plotly figure\n",
        "fig = go.Figure()\n",
        "fig.add_trace(go.Scatter(x=sns_plot.data.car_age, y=sns_plot.data.cost, mode='markers',\n",
        "                         marker=dict(size=8, opacity=0.6),\n",
        "                         text=df1['state_code'] + ', Homeowner: ' + df1['homeowner'].astype(str),\n",
        "                         hoverinfo='text'))\n",
        "\n",
        "fig.update_layout(title='Interactive Pairplot: Car Age vs. Insurance Cost',\n",
        "                  xaxis_title='Car Age',\n",
        "                  yaxis_title='Insurance Cost')\n",
        "\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4q7YpM_Ubxcn"
      },
      "source": [
        "## Fill in Missing Values in Risk Factor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RAg9MFtlq-aU"
      },
      "outputs": [],
      "source": [
        "data = df1.copy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "amVxDYd_Z1rj"
      },
      "outputs": [],
      "source": [
        "df = data.copy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df = df[df['car_age']<26]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A792GVDS6riV"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.cluster import MiniBatchKMeans\n",
        "from scipy.stats import mode\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "import cloudpickle\n",
        "\n",
        "# Assuming 'df' is your DataFrame containing the relevant data\n",
        "\n",
        "# Identify features for clustering\n",
        "features = ['car_age', 'age_oldest', 'age_youngest', 'homeowner', 'group_size', 'married_couple', 'F', 'cost']\n",
        "\n",
        "# Encode categorical features\n",
        "le_state_code = LabelEncoder()\n",
        "le_car_value = LabelEncoder()\n",
        "df['state_code'] = le_state_code.fit_transform(df['state_code'])\n",
        "df['car_value'] = le_car_value.fit_transform(df['car_value'])\n",
        "\n",
        "# Create lookup DataFrames\n",
        "state_code_mapping = pd.DataFrame({'original_value': le_state_code.classes_, 'encoded_value': range(len(le_state_code.classes_))})\n",
        "car_value_mapping = pd.DataFrame({'original_value': le_car_value.classes_, 'encoded_value': range(len(le_car_value.classes_))})\n",
        "\n",
        "# Save the lookup DataFrames as CSV files\n",
        "state_code_mapping.to_csv('state_code_mapping.csv', index=False)\n",
        "car_value_mapping.to_csv('car_value_mapping.csv', index=False)\n",
        "\n",
        "# Prepare full set of features for clustering (both scaled numerical and categorical)\n",
        "encoded_features = df[['state_code', 'car_value']]\n",
        "X_processed = df[features + ['state_code', 'car_value']]\n",
        "\n",
        "# Save the label encoders using cloudpickle\n",
        "with open('le_state_code.pkl', 'wb') as f:\n",
        "    cloudpickle.dump(le_state_code, f)\n",
        "\n",
        "with open('le_car_value.pkl', 'wb') as f:\n",
        "    cloudpickle.dump(le_car_value, f)\n",
        "\n",
        "# Apply MiniBatchKMeans clustering for potentially faster convergence\n",
        "kmeans = MiniBatchKMeans(n_clusters=4, random_state=42)\n",
        "clusters = kmeans.fit_predict(X_processed)\n",
        "\n",
        "# Add clusters to the original dataframe\n",
        "df['cluster'] = clusters\n",
        "\n",
        "# Function to impute missing RISK_FACTOR using vectorized operations\n",
        "def impute_risk_factor(df):\n",
        "    # Calculate mode within each cluster and fillna in 'risk_factor'\n",
        "    def calculate_mode(x):\n",
        "        if not x.dropna().empty:\n",
        "            mode_result = mode(x.dropna())\n",
        "            if isinstance(mode_result.mode, np.ndarray):\n",
        "                return mode_result.mode[0]\n",
        "            else:\n",
        "                return mode_result.mode\n",
        "        else:\n",
        "            return np.nan\n",
        "\n",
        "    cluster_risk_factors = df.groupby('cluster')['risk_factor'].transform(calculate_mode)\n",
        "    return df['risk_factor'].fillna(cluster_risk_factors)\n",
        "\n",
        "# Apply imputation using vectorized function\n",
        "df['risk_factor'] = impute_risk_factor(df)\n",
        "\n",
        "# Drop the cluster column as it's no longer needed\n",
        "df.drop(columns=['cluster'], inplace=True)\n",
        "\n",
        "# Print a message to indicate the mappings have been saved\n",
        "print(\"Lookup files for state code and car value have been saved as 'state_code_mapping.csv' and 'car_value_mapping.csv'.\")\n",
        "\n",
        "# import numpy as np\n",
        "# import pandas as pd\n",
        "# from sklearn.cluster import MiniBatchKMeans\n",
        "# from scipy.stats import mode\n",
        "# from sklearn.preprocessing import LabelEncoder\n",
        "# import cloudpickle\n",
        "\n",
        "# # Assuming 'df' is your DataFrame containing the relevant data\n",
        "\n",
        "# # Identify features for clustering\n",
        "# features = ['car_age', 'age_oldest', 'age_youngest', 'homeowner', 'group_size', 'married_couple', 'F', 'cost']\n",
        "\n",
        "# # Encode categorical features\n",
        "# le_state_code = LabelEncoder()\n",
        "# le_car_value = LabelEncoder()\n",
        "# df['state_code'] = le_state_code.fit_transform(df['state_code'])\n",
        "# df['car_value'] = le_car_value.fit_transform(df['car_value'])\n",
        "\n",
        "# # Prepare full set of features for clustering (both scaled numerical and categorical)\n",
        "# encoded_features = df[['state_code', 'car_value']]\n",
        "# X_processed = df[features + ['state_code', 'car_value']]\n",
        "\n",
        "# # Save the label encoders using cloudpickle\n",
        "# with open('le_state_code.pkl', 'wb') as f:\n",
        "#     cloudpickle.dump(le_state_code, f)\n",
        "\n",
        "# with open('le_car_value.pkl', 'wb') as f:\n",
        "#     cloudpickle.dump(le_car_value, f)\n",
        "\n",
        "# # Apply MiniBatchKMeans clustering for potentially faster convergence\n",
        "# kmeans = MiniBatchKMeans(n_clusters=4, random_state=42)\n",
        "# clusters = kmeans.fit_predict(X_processed)\n",
        "\n",
        "# # Add clusters to the original dataframe\n",
        "# df['cluster'] = clusters\n",
        "\n",
        "# # Function to impute missing RISK_FACTOR using vectorized operations\n",
        "# def impute_risk_factor(df):\n",
        "#     # Calculate mode within each cluster and fillna in 'risk_factor'\n",
        "#     def calculate_mode(x):\n",
        "#         if not x.dropna().empty:\n",
        "#             mode_result = mode(x.dropna())\n",
        "#             if isinstance(mode_result.mode, np.ndarray):\n",
        "#                 return mode_result.mode[0]\n",
        "#             else:\n",
        "#                 return mode_result.mode\n",
        "#         else:\n",
        "#             return np.nan\n",
        "\n",
        "#     cluster_risk_factors = df.groupby('cluster')['risk_factor'].transform(calculate_mode)\n",
        "#     return df['risk_factor'].fillna(cluster_risk_factors)\n",
        "\n",
        "# # Apply imputation using vectorized function\n",
        "# df['risk_factor'] = impute_risk_factor(df)\n",
        "\n",
        "# # Drop the cluster column as it's no longer needed\n",
        "# df.drop(columns=['cluster'], inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8BDUHCnkZw6F",
        "outputId": "6e81bc63-4408-43b9-fd87-18a72e027513"
      },
      "outputs": [],
      "source": [
        "df['risk_factor'].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g7w5bNM16NlQ",
        "outputId": "6e441c32-b3f1-4830-c868-5c0aa332c26d"
      },
      "outputs": [],
      "source": [
        "df.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df.head(3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WqcdqMHlnj0P"
      },
      "outputs": [],
      "source": [
        "# df.to_csv('preprocessed_data.csv', index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df = df.col"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "snowflake_df.columns = map(lambda x: str(x).upper(), df.columns)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "snowflake_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import configparser\n",
        "from sqlalchemy import create_engine\n",
        "import snowflake.connector\n",
        "\n",
        "# Read the configuration file\n",
        "config = configparser.ConfigParser()\n",
        "config.read('snowflake_cred.ini')\n",
        "\n",
        "# Get the Snowflake credentials\n",
        "snowflake_config = config['snowflake']\n",
        "user = snowflake_config['user']\n",
        "password = snowflake_config['password']\n",
        "account = snowflake_config['account']\n",
        "warehouse = snowflake_config['warehouse']\n",
        "database = snowflake_config['database']\n",
        "schema = snowflake_config['schema']\n",
        "table = snowflake_config['table']\n",
        "role = snowflake_config['role']\n",
        "\n",
        "# Create a Snowflake connection string for SQLAlchemy\n",
        "conn = snowflake.connector.connect(\n",
        "    user=user,\n",
        "    password=password,\n",
        "    account=account,\n",
        "    warehouse=warehouse,\n",
        "    database=database,\n",
        "    schema=schema,\n",
        "    role=role,\n",
        ")\n",
        "\n",
        "# Write the DataFrame to the Snowflake table\n",
        "success, nchunks, nrows, _ = write_pandas(conn, snowflake_df, table)\n",
        " \n",
        "if success:\n",
        "    print(f\"Successfully wrote {nrows} rows in {nchunks} chunks to the Snowflake table 'CARINSURANCEDATA'.\")\n",
        "else:\n",
        "    print(\"Failed to write data to the Snowflake table.\")\n",
        " \n",
        "# Close the connection\n",
        "conn.close()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "43_ioRLgmPbi"
      },
      "source": [
        "## Feature Selection"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 161
        },
        "id": "a-5BHrZ9pVxV",
        "outputId": "477d8ee5-7c62-4461-d824-007729382a1d"
      },
      "outputs": [],
      "source": [
        "df.head(2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zpyRUEUIj2yN"
      },
      "outputs": [],
      "source": [
        "data1 = df.copy()\n",
        "data2 = data1.copy()\n",
        "data3 = data1.copy()\n",
        "data4 = data1.copy()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SUwh4oOWmR8K"
      },
      "source": [
        "### 1. Filter Methods - Correlation Matrix with Heatmap:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 793
        },
        "id": "_Bas1ywOjz51",
        "outputId": "ce4b92bc-b98a-4505-c838-bf9d7ceec81d"
      },
      "outputs": [],
      "source": [
        "# Select only numeric columns\n",
        "numeric_cols = data1.select_dtypes(include=[np.number])\n",
        "\n",
        "# Calculate correlation matrix\n",
        "corr_matrix = numeric_cols.corr()\n",
        "\n",
        "# Plot heatmap\n",
        "plt.figure(figsize=(20, 8))\n",
        "sns.heatmap(corr_matrix, annot=True, cmap='coolwarm')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cZsaRjcGmVLg"
      },
      "source": [
        "### 2. Wrapper Methods - Recursive Feature Elimination (RFE):"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DEe1wYi4BCPV"
      },
      "source": [
        "#### Linear Regression"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-d6R0ukPl94m",
        "outputId": "2d66ae63-6044-4d0e-b3af-7c524d3218a4"
      },
      "outputs": [],
      "source": [
        "from sklearn.feature_selection import RFE\n",
        "from sklearn.linear_model import LinearRegression\n",
        "\n",
        "# Assuming your DataFrame is named 'data1'\n",
        "\n",
        "# Select only numeric columns\n",
        "numeric_cols = data2.select_dtypes(include=[np.number])\n",
        "\n",
        "# Separate features and target variable\n",
        "X = numeric_cols.drop('cost', axis=1)\n",
        "y = numeric_cols['cost']\n",
        "\n",
        "# Example using Linear Regression\n",
        "model = LinearRegression()\n",
        "rfe = RFE(model, n_features_to_select=16)\n",
        "fit = rfe.fit(X, y)\n",
        "\n",
        "print(\"Num Features: %s\" % (fit.n_features_))\n",
        "print(\"Selected Features: %s\" % (fit.support_))\n",
        "print(\"Feature Ranking: %s\" % (fit.ranking_))\n",
        "\n",
        "# Get the selected features\n",
        "selected_features = X.columns[fit.support_]\n",
        "print(\"Selected Features Names: %s\" % selected_features)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wbLz-0xdk70C",
        "outputId": "6f39772f-6050-4495-aa7d-2e4c019cdf5b"
      },
      "outputs": [],
      "source": [
        "from sklearn.feature_selection import RFE\n",
        "from sklearn.linear_model import LinearRegression\n",
        "\n",
        "# Select only numeric columns\n",
        "numeric_cols = data2.select_dtypes(include=[np.number])\n",
        "\n",
        "# Separate features and target variable\n",
        "X = numeric_cols.drop('cost', axis=1)\n",
        "y = numeric_cols['cost']\n",
        "\n",
        "# Example using Linear Regression\n",
        "model = LinearRegression()\n",
        "rfe = RFE(model, n_features_to_select=12)\n",
        "fit = rfe.fit(X, y)\n",
        "\n",
        "print(\"Num Features: %s\" % (fit.n_features_))\n",
        "print(\"Selected Features: %s\" % (fit.support_))\n",
        "print(\"Feature Ranking: %s\" % (fit.ranking_))\n",
        "\n",
        "# Get the selected features\n",
        "selected_features = X.columns[fit.support_]\n",
        "print(\"Selected Features Names: %s\" % selected_features)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E0ron-3_mBS8",
        "outputId": "14d932b6-d725-4a3e-f7a1-4080f60c29dd"
      },
      "outputs": [],
      "source": [
        "from sklearn.feature_selection import RFE\n",
        "from sklearn.linear_model import LinearRegression\n",
        "\n",
        "# Select only numeric columns\n",
        "numeric_cols = data2.select_dtypes(include=[np.number])\n",
        "\n",
        "# Separate features and target variable\n",
        "X = numeric_cols.drop('cost', axis=1)\n",
        "y = numeric_cols['cost']\n",
        "\n",
        "# Example using Linear Regression\n",
        "model = LinearRegression()\n",
        "rfe = RFE(model, n_features_to_select=16)\n",
        "fit = rfe.fit(X, y)\n",
        "\n",
        "print(\"Num Features: %s\" % (fit.n_features_))\n",
        "print(\"Selected Features: %s\" % (fit.support_))\n",
        "print(\"Feature Ranking: %s\" % (fit.ranking_))\n",
        "\n",
        "# Get the selected features\n",
        "selected_features = X.columns[fit.support_]\n",
        "print(\"Selected Features Names: %s\" % selected_features)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "data2.head(2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EWSUV4tsmoII"
      },
      "source": [
        "### 3. Embedded Methods - Lasso Regression:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xnG2gx8RmtJ5",
        "outputId": "c593dd0d-3da7-4d2a-c6e1-e41fce32df13"
      },
      "outputs": [],
      "source": [
        "from sklearn.linear_model import Lasso\n",
        "from sklearn.feature_selection import SelectFromModel\n",
        "import numpy as np\n",
        "\n",
        "# Select only numeric columns\n",
        "numeric_cols = data3.select_dtypes(include=[np.number])\n",
        "\n",
        "# Separate features and target variable\n",
        "X = numeric_cols.drop('cost', axis=1)\n",
        "y = numeric_cols['cost']\n",
        "\n",
        "# Lasso model\n",
        "model = Lasso(alpha=0.01)\n",
        "model.fit(X, y)\n",
        "\n",
        "# Select from model\n",
        "selector = SelectFromModel(model, prefit=True)\n",
        "selected_features = selector.get_support()\n",
        "\n",
        "# Get the names of the selected features\n",
        "selected_feature_names = X.columns[selected_features]\n",
        "\n",
        "print(\"Selected Features: %s\" % selected_feature_names)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qrvSIaKyFi4W"
      },
      "source": [
        "## DROP DUPLICATE ROWS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lknoHArRFlxx",
        "outputId": "a16e8183-5a01-4baf-c0a7-77848207c816"
      },
      "outputs": [],
      "source": [
        "final_df = df[['state_code', 'group_size', 'homeowner', 'car_age', 'car_value', 'age_youngest', 'married_couple',\n",
        "       'c_previous', 'duration_previous', 'A', 'B', 'C', 'D', 'E', 'F', 'G', 'cost']]\n",
        "\n",
        "duplicates_count = final_df.duplicated().sum()\n",
        "\n",
        "if duplicates_count > 0:\n",
        "  print('Number of duplicate rows:', duplicates_count)\n",
        "  print('Dropping duplicate rows...')\n",
        "  final_df = final_df.drop_duplicates()\n",
        "  duplicates_count = final_df.duplicated().sum()\n",
        "print('Number of duplicate rows:', duplicates_count)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "final_df.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sqeYzluv_f7c"
      },
      "source": [
        "## Model Training and Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import joblib\n",
        "import pandas as pd\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.metrics import mean_absolute_error, r2_score, mean_squared_error\n",
        "\n",
        "final_df = df[['state_code', 'group_size', 'homeowner', 'car_age', 'car_value', 'age_youngest', 'married_couple', 'c_previous',\n",
        "                'duration_previous', 'A', 'B', 'C', 'D', 'E', 'F', 'G', 'cost']]\n",
        "\n",
        "# Assuming `final_df` is your DataFrame with the relevant features\n",
        "X = final_df.drop('cost', axis=1)\n",
        "y = final_df['cost']\n",
        "\n",
        "# Perform the train-test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "# Define the sets of features to scale\n",
        "features_to_scale_1 = ['car_age']\n",
        "features_to_scale_2 = ['age_youngest']\n",
        "\n",
        "# Create a dictionary to hold the scalers\n",
        "scalers = {}\n",
        "\n",
        "# Create a scaler instance for the first set of features\n",
        "car_age_scaler = MinMaxScaler()\n",
        "X_train_scaled = X_train.copy()\n",
        "X_test_scaled = X_test.copy()\n",
        "X_train_scaled[features_to_scale_1] = car_age_scaler.fit_transform(X_train[features_to_scale_1])\n",
        "X_test_scaled[features_to_scale_1] = car_age_scaler.transform(X_test[features_to_scale_1])\n",
        "scalers['car_age_scaler'] = car_age_scaler\n",
        "\n",
        "# Save the first scaler using joblib\n",
        "joblib.dump(car_age_scaler, 'car_age_scaler.joblib')\n",
        "\n",
        "# Create a scaler instance for the second set of features\n",
        "age_youngest_scaler = MinMaxScaler()\n",
        "X_train_scaled[features_to_scale_2] = age_youngest_scaler.fit_transform(X_train[features_to_scale_2])\n",
        "X_test_scaled[features_to_scale_2] = age_youngest_scaler.transform(X_test[features_to_scale_2])\n",
        "scalers['age_youngest_scaler'] = age_youngest_scaler\n",
        "\n",
        "# Save the second scaler using joblib\n",
        "joblib.dump(age_youngest_scaler, 'age_youngest_scaler.joblib')\n",
        "\n",
        "# Train the model\n",
        "model = RandomForestRegressor(n_estimators=120, random_state=42)\n",
        "model.fit(X_train_scaled, y_train)\n",
        "\n",
        "# Predict on training and test sets\n",
        "y_train_pred = model.predict(X_train_scaled)\n",
        "y_test_pred = model.predict(X_test_scaled)\n",
        "\n",
        "# Compute Mean Absolute Error (MAE)\n",
        "train_mae = mean_absolute_error(y_train, y_train_pred)\n",
        "test_mae = mean_absolute_error(y_test, y_test_pred)\n",
        "\n",
        "# Compute R2 scores\n",
        "train_r2 = r2_score(y_train, y_train_pred)\n",
        "test_r2 = r2_score(y_test, y_test_pred)\n",
        "\n",
        "# Compute Mean Squared Error (MSE)\n",
        "train_mse = mean_squared_error(y_train, y_train_pred)\n",
        "test_mse = mean_squared_error(y_test, y_test_pred)\n",
        "\n",
        "print(f\"Train MAE: {train_mae}\")\n",
        "print(f\"Test MAE: {test_mae}\")\n",
        "\n",
        "print(f\"\\nTrain R-squared Score: {train_r2}\")\n",
        "print(f\"Test R-squared Score: {test_r2}\")\n",
        "\n",
        "print(f\"\\nTrain MSE: {train_mse}\")\n",
        "print(f\"Test MSE: {test_mse}\")\n",
        "\n",
        "# Save the model\n",
        "joblib.dump(model, 'model.joblib')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import joblib\n",
        "import pandas as pd\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.metrics import mean_absolute_error, r2_score, mean_squared_error\n",
        "\n",
        "final_df = df[['state_code', 'group_size', 'homeowner', 'car_age', 'car_value', 'age_youngest', 'married_couple', 'c_previous',\n",
        "                'duration_previous', 'A', 'B', 'C', 'D', 'E', 'F', 'G', 'cost']]\n",
        "\n",
        "# Assuming `final_df` is your DataFrame with the relevant features\n",
        "X = final_df.drop('cost', axis=1)\n",
        "y = final_df['cost']\n",
        "\n",
        "# Perform the train-test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "# Define the sets of features to scale\n",
        "features_to_scale_1 = ['car_age']\n",
        "features_to_scale_2 = ['age_youngest']\n",
        "\n",
        "# Create a dictionary to hold the scalers\n",
        "scalers = {}\n",
        "\n",
        "# Create a scaler instance for the first set of features\n",
        "car_age_scaler = MinMaxScaler()\n",
        "X_train_scaled = X_train.copy()\n",
        "X_test_scaled = X_test.copy()\n",
        "X_train_scaled[features_to_scale_1] = car_age_scaler.fit_transform(X_train[features_to_scale_1])\n",
        "X_test_scaled[features_to_scale_1] = car_age_scaler.transform(X_test[features_to_scale_1])\n",
        "scalers['car_age_scaler'] = car_age_scaler\n",
        "\n",
        "# Save the first scaler using joblib\n",
        "joblib.dump(car_age_scaler, 'car_age_scaler.joblib')\n",
        "\n",
        "# Create a scaler instance for the second set of features\n",
        "age_youngest_scaler = MinMaxScaler()\n",
        "X_train_scaled[features_to_scale_2] = age_youngest_scaler.fit_transform(X_train[features_to_scale_2])\n",
        "X_test_scaled[features_to_scale_2] = age_youngest_scaler.transform(X_test[features_to_scale_2])\n",
        "scalers['age_youngest_scaler'] = age_youngest_scaler\n",
        "\n",
        "# Save the second scaler using joblib\n",
        "joblib.dump(age_youngest_scaler, 'age_youngest_scaler.joblib')\n",
        "\n",
        "# Train the model\n",
        "model = RandomForestRegressor(n_estimators=120, random_state=42)\n",
        "model.fit(X_train_scaled, y_train)\n",
        "\n",
        "# Predict on training and test sets\n",
        "y_train_pred = model.predict(X_train_scaled)\n",
        "y_test_pred = model.predict(X_test_scaled)\n",
        "\n",
        "# Compute Mean Absolute Error (MAE)\n",
        "train_mae = mean_absolute_error(y_train, y_train_pred)\n",
        "test_mae = mean_absolute_error(y_test, y_test_pred)\n",
        "\n",
        "# Compute R2 scores\n",
        "train_r2 = r2_score(y_train, y_train_pred)\n",
        "test_r2 = r2_score(y_test, y_test_pred)\n",
        "\n",
        "# Compute Mean Squared Error (MSE)\n",
        "train_mse = mean_squared_error(y_train, y_train_pred)\n",
        "test_mse = mean_squared_error(y_test, y_test_pred)\n",
        "\n",
        "print(f\"Train MAE: {train_mae}\")\n",
        "print(f\"Test MAE: {test_mae}\")\n",
        "\n",
        "print(f\"\\nTrain R-squared Score: {train_r2}\")\n",
        "print(f\"Test R-squared Score: {test_r2}\")\n",
        "\n",
        "print(f\"\\nTrain MSE: {train_mse}\")\n",
        "print(f\"Test MSE: {test_mse}\")\n",
        "\n",
        "# Save the model\n",
        "joblib.dump(model, 'model.joblib')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Who3bmPI95xw",
        "outputId": "8d306c7b-e45e-4f29-8474-f8a7e25b99f4"
      },
      "outputs": [],
      "source": [
        "import joblib\n",
        "import pandas as pd\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.metrics import mean_absolute_error, r2_score, mean_squared_error\n",
        "\n",
        "final_df = df[['state_code', 'group_size', 'homeowner', 'car_age', 'car_value', 'risk_factor', 'age_youngest', 'married_couple', 'c_previous',\n",
        "               'duration_previous', 'A', 'B', 'C', 'D', 'E', 'F', 'G', 'cost']]\n",
        "\n",
        "final_df.head()\n",
        "\n",
        "# Assuming `final_df` is your DataFrame with the relevant features\n",
        "X = final_df.drop('cost', axis=1)\n",
        "y = final_df['cost']\n",
        "\n",
        "# Perform the train-test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "# Define the sets of features to scale\n",
        "features_to_scale_1 = ['car_age']\n",
        "features_to_scale_2 = ['age_youngest']\n",
        "\n",
        "# Create a dictionary to hold the scalers\n",
        "scalers = {}\n",
        "\n",
        "# Create a scaler instance for the first set of features\n",
        "car_age_scaler = MinMaxScaler()\n",
        "X_train_scaled = X_train.copy()\n",
        "X_test_scaled = X_test.copy()\n",
        "X_train_scaled[features_to_scale_1] = car_age_scaler.fit_transform(X_train[features_to_scale_1])\n",
        "X_test_scaled[features_to_scale_1] = car_age_scaler.transform(X_test[features_to_scale_1])\n",
        "scalers['car_age_scaler'] = car_age_scaler\n",
        "\n",
        "# Save the first scaler using joblib\n",
        "joblib.dump(car_age_scaler, 'car_age_scaler.joblib')\n",
        "\n",
        "# Create a scaler instance for the second set of features\n",
        "age_youngest_scaler = MinMaxScaler()\n",
        "X_train_scaled[features_to_scale_2] = age_youngest_scaler.fit_transform(X_train[features_to_scale_2])\n",
        "X_test_scaled[features_to_scale_2] = age_youngest_scaler.transform(X_test[features_to_scale_2])\n",
        "scalers['age_youngest_scaler'] = age_youngest_scaler\n",
        "\n",
        "# Save the second scaler using joblib\n",
        "joblib.dump(age_youngest_scaler, 'age_youngest_scaler.joblib')\n",
        "\n",
        "# Train the model\n",
        "model = RandomForestRegressor(random_state=42)\n",
        "model.fit(X_train_scaled, y_train)\n",
        "\n",
        "# Predict on training and test sets\n",
        "y_train_pred = model.predict(X_train_scaled)\n",
        "y_test_pred = model.predict(X_test_scaled)\n",
        "\n",
        "# Compute Mean Absolute Error (MAE)\n",
        "train_mae = mean_absolute_error(y_train, y_train_pred)\n",
        "test_mae = mean_absolute_error(y_test, y_test_pred)\n",
        "\n",
        "# Compute R2 scores\n",
        "train_r2 = r2_score(y_train, y_train_pred)\n",
        "test_r2 = r2_score(y_test, y_test_pred)\n",
        "\n",
        "# Compute Mean Squared Error (MSE)\n",
        "train_mse = mean_squared_error(y_train, y_train_pred)\n",
        "test_mse = mean_squared_error(y_test, y_test_pred)\n",
        "\n",
        "print(f\"Train MAE: {train_mae}\")\n",
        "print(f\"Test MAE: {test_mae}\")\n",
        "\n",
        "print(f\"\\nTrain R-squared Score: {train_r2}\")\n",
        "print(f\"Test R-squared Score: {test_r2}\")\n",
        "\n",
        "print(f\"\\nTrain MSE: {train_mse}\")\n",
        "print(f\"Test MSE: {test_mse}\")\n",
        "\n",
        "# Save the model\n",
        "joblib.dump(model, 'model.joblib')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gjEScdxfusrF"
      },
      "source": [
        "### *** Model Training 00 - Random Forest Regressor (15 features) - (0.87536)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "vgHeApyhusrH",
        "outputId": "493393b8-2fdc-4599-8592-b00aa1b3e74f"
      },
      "outputs": [],
      "source": [
        "final_df = df[['state_code', 'group_size', 'homeowner', 'car_age', 'car_value', 'risk_factor', 'age_youngest', 'married_couple', 'c_previous',\n",
        "               'duration_previous', 'A', 'B', 'C', 'E', 'F', 'G', 'cost']]\n",
        "\n",
        "# # Converting some columns from float to int\n",
        "# columns_to_convert = ['state_code', 'group_size', 'homeowner', 'car_age', 'risk_factor', 'age_youngest', 'married_couple', 'c_previous', 'duration_previous', 'A', 'B', 'C', 'E', 'F', 'G']\n",
        "\n",
        "# final_df[columns_to_convert] = final_df[columns_to_convert].astype(int)\n",
        "\n",
        "final_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WnGYCwYdkNl2",
        "outputId": "3e2b9206-695f-4ab9-bd02-3e3790487491"
      },
      "outputs": [],
      "source": [
        "final_df.dtypes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZI2g_KxbusrJ"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Assuming `df` is your DataFrame with the relevant features\n",
        "X = final_df.drop('cost', axis=1)\n",
        "y = final_df['cost']\n",
        "\n",
        "# Perform the train-test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L54r4jp8usrJ",
        "outputId": "42939589-ce85-42ea-8ff3-8cc0b20044ed"
      },
      "outputs": [],
      "source": [
        "# Define the sets of features to scale\n",
        "features_to_scale_1 = ['car_age']\n",
        "features_to_scale_2 = ['age_youngest']\n",
        "\n",
        "# Create a dictionary to hold the scalers\n",
        "scalers = {}\n",
        "\n",
        "# Create a scaler instance for the first set of features\n",
        "car_age_scaler = MinMaxScaler()\n",
        "X_train_scaled = X_train.copy()\n",
        "X_test_scaled = X_test.copy()\n",
        "X_train_scaled[features_to_scale_1] = car_age_scaler.fit_transform(X_train[features_to_scale_1])\n",
        "X_test_scaled[features_to_scale_1] = car_age_scaler.transform(X_test[features_to_scale_1])\n",
        "scalers['car_age_scaler'] = car_age_scaler\n",
        "\n",
        "# Save the first scaler using joblib\n",
        "joblib.dump(car_age_scaler, 'car_age_scaler.joblib')\n",
        "\n",
        "# Create a scaler instance for the second set of features\n",
        "age_youngest_scaler = MinMaxScaler()\n",
        "X_train_scaled[features_to_scale_2] = age_youngest_scaler.fit_transform(X_train[features_to_scale_2])\n",
        "X_test_scaled[features_to_scale_2] = age_youngest_scaler.transform(X_test[features_to_scale_2])\n",
        "scalers['age_youngest_scaler'] = age_youngest_scaler\n",
        "\n",
        "# Save the second scaler using joblib\n",
        "joblib.dump(age_youngest_scaler, 'age_youngest_scaler.joblib')\n",
        "\n",
        "# Save the dictionary of scalers as a pickle file if needed\n",
        "joblib.dump(scalers, 'scalers.joblib')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q_RTVpDThf8G",
        "outputId": "98464f73-6e6d-4a3e-d4bc-f0eda31765d5"
      },
      "outputs": [],
      "source": [
        "X_train_scaled.dtypes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dYzmWBk6usrL",
        "outputId": "32d32474-6dc3-4b27-b2cb-ead7f71bbe99"
      },
      "outputs": [],
      "source": [
        "print(X_train_scaled.shape)\n",
        "print(X_test_scaled.shape)\n",
        "print(y_train.shape)\n",
        "print(y_test.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 75
        },
        "id": "gZrIwOn5usrM",
        "outputId": "c2356cb6-293a-415a-be07-d64a89787769"
      },
      "outputs": [],
      "source": [
        "# Choose a model and train it\n",
        "model = RandomForestRegressor(random_state=42)\n",
        "model.fit(X_train_scaled, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4cPcRhPousrM",
        "outputId": "76944fc1-d245-4ab0-9a0e-abba231bfac2"
      },
      "outputs": [],
      "source": [
        "# Predict on training and test sets\n",
        "y_train_pred = model.predict(X_train_scaled)\n",
        "y_test_pred = model.predict(X_test_scaled)\n",
        "\n",
        "# Compute Mean Absolute Error (MAE)\n",
        "train_mae = mean_absolute_error(y_train, y_train_pred)\n",
        "test_mae = mean_absolute_error(y_test, y_test_pred)\n",
        "\n",
        "# Compute R2 scores\n",
        "train_r2 = r2_score(y_train, y_train_pred)\n",
        "test_r2 = r2_score(y_test, y_test_pred)\n",
        "\n",
        "# Compute Mean Squared Error\n",
        "train_mse = mean_squared_error(y_train, y_train_pred)\n",
        "test_mse = mean_squared_error(y_test, y_test_pred)\n",
        "\n",
        "print(f\"Train MAE: {train_mae}\")\n",
        "print(f\"Test MAE: {test_mae}\")\n",
        "\n",
        "print(f\"\\nTrain R-squared Score: {train_r2}\")\n",
        "print(f\"Test R-squared Score: {test_r2}\")\n",
        "\n",
        "print(f\"\\nTrain MSE: {train_mse}\")\n",
        "print(f\"Test MSE: {test_mse}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ugDJ39vsFxLU",
        "outputId": "7c737fe9-db37-463e-c27a-9ebffb2354ae"
      },
      "outputs": [],
      "source": [
        "# Save the model\n",
        "joblib.dump(model, 'model.joblib')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JJsR8uumIt7h"
      },
      "source": [
        "### *** Model Training 0 - Random Forest Regressor (16 features) - (0.87489)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mfa_yao_It7j",
        "outputId": "15019c82-8a3a-4cb0-84da-94cf6118c7a5"
      },
      "outputs": [],
      "source": [
        "final_df = df[['record_type', 'state_code', 'group_size', 'homeowner', 'car_age', 'car_value', 'risk_factor', 'age_youngest', 'married_couple',\n",
        "       'c_previous', 'duration_previous', 'A', 'C', 'E', 'F', 'G', 'cost']]\n",
        "final_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NZ8EAN0MIt7k"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Assuming `final_df` is your DataFrame with the relevant features and target 'cost'\n",
        "X = final_df.drop('cost', axis=1)\n",
        "y = final_df['cost']\n",
        "\n",
        "# Perform the train-test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-ilvxYoFNC6Q"
      },
      "outputs": [],
      "source": [
        "import pickle\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "# Assume X_train and X_test are defined elsewhere in your script\n",
        "\n",
        "# Define the sets of features to scale\n",
        "features_to_scale_1 = ['car_age']\n",
        "features_to_scale_2 = ['age_youngest']\n",
        "\n",
        "# Create a dictionary to hold the scalers\n",
        "scalers = {}\n",
        "\n",
        "# Create a scaler instance for the first set of features\n",
        "car_age_scaler = MinMaxScaler()\n",
        "X_train_scaled = X_train.copy()\n",
        "X_test_scaled = X_test.copy()\n",
        "X_train_scaled[features_to_scale_1] = car_age_scaler.fit_transform(X_train[features_to_scale_1])\n",
        "X_test_scaled[features_to_scale_1] = car_age_scaler.transform(X_test[features_to_scale_1])\n",
        "scalers['car_age_scaler'] = car_age_scaler\n",
        "\n",
        "# Create a scaler instance for the second set of features\n",
        "age_youngest_scaler = MinMaxScaler()\n",
        "X_train_scaled[features_to_scale_2] = age_youngest_scaler.fit_transform(X_train[features_to_scale_2])\n",
        "X_test_scaled[features_to_scale_2] = age_youngest_scaler.transform(X_test[features_to_scale_2])\n",
        "scalers['age_youngest_scaler'] = age_youngest_scaler\n",
        "\n",
        "# Save the dictionary of scalers as a pickle file\n",
        "with open('scalers.pkl', 'wb') as f:\n",
        "    pickle.dump(scalers, f)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WD7eKEWjIt7m",
        "outputId": "5969c03d-3bc2-4207-dfa7-269f6959fbe0"
      },
      "outputs": [],
      "source": [
        "print(X_train_scaled.shape)\n",
        "print(X_test_scaled.shape)\n",
        "print(y_train.shape)\n",
        "print(y_test.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 75
        },
        "id": "nh_4G8RdIt7m",
        "outputId": "83bc6a43-385e-4f8d-eae1-c52f754691a5"
      },
      "outputs": [],
      "source": [
        "# Choose a model and train it\n",
        "model = RandomForestRegressor(n_estimators=120, random_state=42)\n",
        "model.fit(X_train_scaled, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "94ycCNVcIsZL"
      },
      "outputs": [],
      "source": [
        "# Save the dictionary of model as a pickle file\n",
        "with open('model.pkl', 'wb') as f:\n",
        "    pickle.dump(model, f)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N-9u5kwiIt7m",
        "outputId": "cd91a415-2f48-4ae8-be4d-235fa9fe4e78"
      },
      "outputs": [],
      "source": [
        "# Predict on training and test sets\n",
        "y_train_pred = model.predict(X_train_scaled)\n",
        "y_test_pred = model.predict(X_test_scaled)\n",
        "\n",
        "# Compute Mean Absolute Error (MAE)\n",
        "train_mae = mean_absolute_error(y_train, y_train_pred)\n",
        "test_mae = mean_absolute_error(y_test, y_test_pred)\n",
        "\n",
        "# Compute R2 scores\n",
        "train_r2 = r2_score(y_train, y_train_pred)\n",
        "test_r2 = r2_score(y_test, y_test_pred)\n",
        "\n",
        "# Compute Mean Squared Error\n",
        "train_mse = mean_squared_error(y_train, y_train_pred)\n",
        "test_mse = mean_squared_error(y_test, y_test_pred)\n",
        "\n",
        "print(f\"Train MAE: {train_mae}\")\n",
        "print(f\"Test MAE: {test_mae}\")\n",
        "\n",
        "print(f\"\\nTrain R-squared Score: {train_r2}\")\n",
        "print(f\"Test R-squared Score: {test_r2}\")\n",
        "\n",
        "print(f\"\\nTrain MSE: {train_mse}\")\n",
        "print(f\"Test MSE: {test_mse}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nFig3WgiAfg7"
      },
      "source": [
        "### Model Training 1 - Random Forest Regressor (13 features) SC-x, B-x, G-x - (0.8270)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BiJq0zaFzK4k"
      },
      "outputs": [],
      "source": [
        "final_df = df[['homeowner', 'group_size', 'car_age', 'car_value', 'risk_factor', 'age_oldest', 'age_youngest', 'married_couple', 'c_previous', 'duration_previous',\n",
        "              'A', 'E', 'F', 'cost']]\n",
        "final_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lee6iXBGsDfu"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Assuming `df` is your DataFrame with the relevant features\n",
        "X = final_df.drop('cost', axis=1)\n",
        "y = final_df['cost']\n",
        "\n",
        "# Perform the train-test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u4NT5gYy0fkd"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Define the features to scale\n",
        "features_to_scale = ['car_age', 'age_oldest', 'age_youngest']\n",
        "\n",
        "# Create a scaler instance\n",
        "scaler = StandardScaler()\n",
        "\n",
        "# Fit the scaler on the training data and transform training data\n",
        "X_train_scaled = X_train.copy()\n",
        "X_train_scaled[features_to_scale] = scaler.fit_transform(X_train[features_to_scale])\n",
        "\n",
        "# Transform test data using the scaler fitted on training data\n",
        "X_test_scaled = X_test.copy()\n",
        "X_test_scaled[features_to_scale] = scaler.transform(X_test[features_to_scale])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mT72Du7y1XEL"
      },
      "outputs": [],
      "source": [
        "print(X_train_scaled.shape)\n",
        "print(X_test_scaled.shape)\n",
        "print(y_train.shape)\n",
        "print(y_test.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zNRoV8dg1AB1"
      },
      "outputs": [],
      "source": [
        "# Step 2: Choose a model and train it\n",
        "model = RandomForestRegressor(random_state=42)\n",
        "model.fit(X_train_scaled, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dtObv8Bb1JPl"
      },
      "outputs": [],
      "source": [
        "# Step 3: Evaluate the model\n",
        "y_pred = model.predict(X_test_scaled)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P4bbf8iO1MdY"
      },
      "outputs": [],
      "source": [
        "# Compute Mean Absolute Error (MAE)\n",
        "mae = mean_absolute_error(y_test, y_pred)\n",
        "\n",
        "# Compute R2 score (coefficient of determination)\n",
        "r2 = r2_score(y_test, y_pred)\n",
        "\n",
        "# Compute Mean Squared Error\n",
        "mse = mean_squared_error(y_test, y_pred)\n",
        "\n",
        "print(f\"Mean Absolute Error (MAE): {mae}\")\n",
        "print(f\"R-squared Score (R2): {r2}\")\n",
        "print(f\"Mean Squared Error: {mse}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rE-RTZuiAmsy"
      },
      "source": [
        "### Model Training 2 - Random Forest Regressor (15 features) 0.8737858"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Sg9zbq3kAms1"
      },
      "outputs": [],
      "source": [
        "final_df = df[['state_code', 'record_type', 'group_size', 'homeowner', 'car_age', 'car_value', 'risk_factor', 'age_youngest', 'married_couple',\n",
        "       'c_previous', 'duration_previous', 'A', 'E', 'F', 'G', 'cost']]\n",
        "final_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CxL_TDPosQRA"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Assuming `df` is your DataFrame with the relevant features\n",
        "X = final_df.drop('cost', axis=1)\n",
        "y = final_df['cost']\n",
        "\n",
        "# Perform the train-test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "84aPVxBEAms3"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "# Define the features to scale\n",
        "features_to_scale = ['car_age', 'age_youngest']\n",
        "\n",
        "# Create a scaler instance\n",
        "scaler = MinMaxScaler()\n",
        "\n",
        "# Fit the scaler on the training data and transform training data\n",
        "X_train_scaled = X_train.copy()\n",
        "X_train_scaled[features_to_scale] = scaler.fit_transform(X_train[features_to_scale])\n",
        "\n",
        "# Transform test data using the scaler fitted on training data\n",
        "X_test_scaled = X_test.copy()\n",
        "X_test_scaled[features_to_scale] = scaler.transform(X_test[features_to_scale])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vWNhC0EtAms6"
      },
      "outputs": [],
      "source": [
        "print(X_train_scaled.shape)\n",
        "print(X_test_scaled.shape)\n",
        "print(y_train.shape)\n",
        "print(y_test.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-OU9-byIAms8"
      },
      "outputs": [],
      "source": [
        "# Step 2: Choose a model and train it\n",
        "model = RandomForestRegressor(n_estimators=120, random_state=42)\n",
        "model.fit(X_train_scaled, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b202cgHeAms9"
      },
      "outputs": [],
      "source": [
        "# Predict on training and test sets\n",
        "y_train_pred = model.predict(X_train_scaled)\n",
        "y_test_pred = model.predict(X_test_scaled)\n",
        "\n",
        "# Compute Mean Absolute Error (MAE)\n",
        "train_mae = mean_absolute_error(y_train, y_train_pred)\n",
        "test_mae = mean_absolute_error(y_test, y_test_pred)\n",
        "\n",
        "# Compute R2 scores\n",
        "train_r2 = r2_score(y_train, y_train_pred)\n",
        "test_r2 = r2_score(y_test, y_test_pred)\n",
        "\n",
        "# Compute Mean Squared Error\n",
        "train_mse = mean_squared_error(y_train, y_train_pred)\n",
        "test_mse = mean_squared_error(y_test, y_test_pred)\n",
        "\n",
        "print(f\"Train MAE: {train_mae}\")\n",
        "print(f\"Test MAE: {test_mae}\")\n",
        "\n",
        "print(f\"\\nTrain R-squared Score: {train_r2}\")\n",
        "print(f\"Test R-squared Score: {test_r2}\")\n",
        "\n",
        "print(f\"\\nTrain MSE: {train_mse}\")\n",
        "print(f\"Test MSE: {test_mse}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MBqWuZAzBPeC"
      },
      "source": [
        "### Model Training 3 - DTR, LR, KNR, GBR (14 features) X\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UpsqQXwwBPeD"
      },
      "outputs": [],
      "source": [
        "# final_df = df[['homeowner', 'group_size', 'car_age', 'car_value', 'risk_factor', 'age_oldest', 'age_youngest', 'married_couple', 'c_previous', 'duration_previous',\n",
        "#               'A', 'E', 'F', 'G', 'cost']]\n",
        "final_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DRuNsGuDsmfL"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Assuming `df` is your DataFrame with the relevant features\n",
        "X = final_df.drop('cost', axis=1)\n",
        "y = final_df['cost']\n",
        "\n",
        "# Perform the train-test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fX9pSQibBPeF"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "# Define the features to scale\n",
        "features_to_scale = ['car_age', 'age_youngest']\n",
        "\n",
        "# Create a scaler instance\n",
        "scaler = MinMaxScaler()\n",
        "\n",
        "# Fit the scaler on the training data and transform training data\n",
        "X_train_scaled = X_train.copy()\n",
        "X_train_scaled[features_to_scale] = scaler.fit_transform(X_train[features_to_scale])\n",
        "\n",
        "# Transform test data using the scaler fitted on training data\n",
        "X_test_scaled = X_test.copy()\n",
        "X_test_scaled[features_to_scale] = scaler.transform(X_test[features_to_scale])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-CQWKz0PBPeG"
      },
      "outputs": [],
      "source": [
        "print(X_train_scaled.shape)\n",
        "print(X_test_scaled.shape)\n",
        "print(y_train.shape)\n",
        "print(y_test.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "It2jbEWIBp4Q"
      },
      "outputs": [],
      "source": [
        "# Example usage of different regressors\n",
        "models = {\n",
        "    'Decision Tree Regressor': DecisionTreeRegressor(),\n",
        "    'Linear Regression': LinearRegression(),\n",
        "    'K-Nearest Neighbors': KNeighborsRegressor(),\n",
        "    'Gradient Boosting': GradientBoostingRegressor()\n",
        "}\n",
        "\n",
        "# Iterate over models and fit/evaluate as needed\n",
        "for name, model in models.items():\n",
        "    model.fit(X_train_scaled, y_train)\n",
        "\n",
        "    y_pred = model.predict(X_test_scaled)\n",
        "\n",
        "    mae = mean_absolute_error(y_test, y_pred)\n",
        "    r2 = r2_score(y_test, y_pred)\n",
        "\n",
        "    print(f\"Model: {name}\")\n",
        "    print(f\"  Mean Absolute Error (MAE): {mae}\")\n",
        "    print(f\"  R-squared Score (R2): {r2}\")\n",
        "    print()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gxiW33RDCZo9"
      },
      "source": [
        "### *** Model Training 4 - Random Forest Regressor (14 features) B-x, AO-x - (0.875296)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KLsgxbgsCZpB"
      },
      "outputs": [],
      "source": [
        "final_df = df[['state_code', 'homeowner', 'group_size', 'car_age', 'car_value', 'risk_factor', 'age_youngest', 'married_couple', 'c_previous', 'duration_previous',\n",
        "              'A', 'E', 'F', 'G', 'cost']]\n",
        "final_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D9KKSKsOCZpD"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Assuming `df` is your DataFrame with the relevant features\n",
        "X = final_df.drop('cost', axis=1)\n",
        "y = final_df['cost']\n",
        "\n",
        "# Perform the train-test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yUl0DFDFCZpE"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Define the features to scale\n",
        "features_to_scale = ['car_age', 'age_youngest']\n",
        "\n",
        "# Create a scaler instance\n",
        "scaler = StandardScaler()\n",
        "\n",
        "# Fit the scaler on the training data and transform training data\n",
        "X_train_scaled = X_train.copy()\n",
        "X_train_scaled[features_to_scale] = scaler.fit_transform(X_train[features_to_scale])\n",
        "\n",
        "# Transform test data using the scaler fitted on training data\n",
        "X_test_scaled = X_test.copy()\n",
        "X_test_scaled[features_to_scale] = scaler.transform(X_test[features_to_scale])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zTh7pnSSCZpI"
      },
      "outputs": [],
      "source": [
        "print(X_train_scaled.shape)\n",
        "print(X_test_scaled.shape)\n",
        "print(y_train.shape)\n",
        "print(y_test.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nGRRJQ7YCZpJ"
      },
      "outputs": [],
      "source": [
        "# Step 2: Choose a model and train it\n",
        "model = RandomForestRegressor(random_state=42)\n",
        "model.fit(X_train_scaled, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Nn31wGf-CZpK"
      },
      "outputs": [],
      "source": [
        "# Step 3: Evaluate the model\n",
        "y_pred = model.predict(X_test_scaled)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MhShHXyOCZpK"
      },
      "outputs": [],
      "source": [
        "# Compute Mean Absolute Error (MAE)\n",
        "mae = mean_absolute_error(y_test, y_pred)\n",
        "\n",
        "# Compute R2 score (coefficient of determination)\n",
        "r2 = r2_score(y_test, y_pred)\n",
        "\n",
        "# Compute Mean Squared Error\n",
        "mse = mean_squared_error(y_test, y_pred)\n",
        "\n",
        "print(f\"Mean Absolute Error (MAE): {mae}\")\n",
        "print(f\"R-squared Score (R2): {r2}\")\n",
        "print(f\"Mean Squared Error: {mse}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3LVrb7VnUGUX"
      },
      "source": [
        "### Model Training 5 - Random Forest Regressor (16 features) AO-x, CA-x, G-x (0.86228)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0fLlTDKJUGUa"
      },
      "outputs": [],
      "source": [
        "final_df = df[['state_code', 'homeowner', 'group_size', 'car_age', 'car_value', 'risk_factor', 'age_youngest', 'married_couple', 'c_previous', 'duration_previous',\n",
        "              'A', 'B', 'C', 'E', 'F', 'G', 'cost']]\n",
        "final_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AV2FcptJUGUb"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Assuming `df` is your DataFrame with the relevant features\n",
        "X = final_df.drop('cost', axis=1)\n",
        "y = final_df['cost']\n",
        "\n",
        "# Perform the train-test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KzYy-BkfUGUc"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Define the features to scale\n",
        "features_to_scale = ['car_age', 'age_youngest']\n",
        "\n",
        "# Create a scaler instance\n",
        "scaler = StandardScaler()\n",
        "\n",
        "# Fit the scaler on the training data and transform training data\n",
        "X_train_scaled = X_train.copy()\n",
        "X_train_scaled[features_to_scale] = scaler.fit_transform(X_train[features_to_scale])\n",
        "\n",
        "# Transform test data using the scaler fitted on training data\n",
        "X_test_scaled = X_test.copy()\n",
        "X_test_scaled[features_to_scale] = scaler.transform(X_test[features_to_scale])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r6U0Uax2UGUd"
      },
      "outputs": [],
      "source": [
        "print(X_train_scaled.shape)\n",
        "print(X_test_scaled.shape)\n",
        "print(y_train.shape)\n",
        "print(y_test.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X3vP2Pq1UGUe"
      },
      "outputs": [],
      "source": [
        "# Step 2: Choose a model and train it\n",
        "model = RandomForestRegressor(random_state=42)\n",
        "model.fit(X_train_scaled, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "95kQMKVvUGUf"
      },
      "outputs": [],
      "source": [
        "# Step 3: Evaluate the model\n",
        "y_pred = model.predict(X_test_scaled)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AscqVekAUGUg"
      },
      "outputs": [],
      "source": [
        "# Compute Mean Absolute Error (MAE)\n",
        "mae = mean_absolute_error(y_test, y_pred)\n",
        "\n",
        "# Compute R2 score (coefficient of determination)\n",
        "r2 = r2_score(y_test, y_pred)\n",
        "\n",
        "# Compute Mean Squared Error\n",
        "mse = mean_squared_error(y_test, y_pred)\n",
        "\n",
        "print(f\"Mean Absolute Error (MAE): {mae}\")\n",
        "print(f\"R-squared Score (R2): {r2}\")\n",
        "print(f\"Mean Squared Error: {mse}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lMenekuQGDEF"
      },
      "source": [
        "### *** Model Training 6 - Random Forest Regressor (16 features) - (0.8767)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lQUIRCxsGDEH"
      },
      "outputs": [],
      "source": [
        "final_df = df[['state_code', 'homeowner', 'group_size', 'car_age', 'car_value', 'risk_factor', 'age_oldest', 'age_youngest', 'married_couple', 'c_previous', 'duration_previous',\n",
        "              'A', 'B', 'E', 'F', 'G', 'cost']]\n",
        "final_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ygMtFk2rGDEK"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Assuming `df` is your DataFrame with the relevant features\n",
        "X = final_df.drop('cost', axis=1)\n",
        "y = final_df['cost']\n",
        "\n",
        "# Perform the train-test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jFI_SSeWGDEL"
      },
      "outputs": [],
      "source": [
        "# Define the sets of features to scale\n",
        "features_to_scale_1 = ['car_age']\n",
        "features_to_scale_2 = ['age_youngest']\n",
        "\n",
        "# Create a dictionary to hold the scalers\n",
        "scalers = {}\n",
        "\n",
        "# Create a scaler instance for the first set of features and fit it\n",
        "car_age_scaler = MinMaxScaler()\n",
        "X_train_scaled = X_train.copy()\n",
        "X_train_scaled[features_to_scale_1] = car_age_scaler.fit_transform(X_train[features_to_scale_1])\n",
        "X_test_scaled = X_test.copy()\n",
        "X_test_scaled[features_to_scale_1] = car_age_scaler.transform(X_test[features_to_scale_1])\n",
        "scalers['car_age_scaler'] = car_age_scaler\n",
        "\n",
        "# Create a scaler instance for the second set of features and fit it\n",
        "age_youngest_scaler = MinMaxScaler()\n",
        "X_train_scaled = X_train.copy()\n",
        "X_train_scaled[features_to_scale_2] = age_youngest_scaler.fit_transform(X_train[features_to_scale_2])\n",
        "X_test_scaled = X_test.copy()\n",
        "X_test_scaled[features_to_scale_2] = age_youngest_scaler.transform(X_test[features_to_scale_2])\n",
        "scalers['age_youngest_scaler'] = age_youngest_scaler\n",
        "\n",
        "# Save the dictionary of scalers as a pickle file\n",
        "with open('scalers.pkl', 'wb') as f:\n",
        "    pickle.dump(scalers, f)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nh_JSz6zGDEN"
      },
      "outputs": [],
      "source": [
        "print(X_train_scaled.shape)\n",
        "print(X_test_scaled.shape)\n",
        "print(y_train.shape)\n",
        "print(y_test.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pEo3SnfrGDEO"
      },
      "outputs": [],
      "source": [
        "# Step 2: Choose a model and train it\n",
        "model = RandomForestRegressor(random_state=42)\n",
        "model.fit(X_train_scaled, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T7FdzyF-GDEP"
      },
      "outputs": [],
      "source": [
        "# Step 3: Evaluate the model\n",
        "y_pred = model.predict(X_test_scaled)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OSl-CEjKGDEP"
      },
      "outputs": [],
      "source": [
        "# Compute Mean Absolute Error (MAE)\n",
        "mae = mean_absolute_error(y_test, y_pred)\n",
        "\n",
        "# Compute R2 score (coefficient of determination)\n",
        "r2 = r2_score(y_test, y_pred)\n",
        "\n",
        "# Compute Mean Squared Error\n",
        "mse = mean_squared_error(y_test, y_pred)\n",
        "\n",
        "print(f\"Mean Absolute Error (MAE): {mae}\")\n",
        "print(f\"R-squared Score (R2): {r2}\")\n",
        "print(f\"Mean Squared Error: {mse}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mJCbZmA9dX9w"
      },
      "source": [
        "### *** Model Training 7 - Random Forest Regressor (14 features) B-x, G-x - (0.86778)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wItr5CuydX9y"
      },
      "outputs": [],
      "source": [
        "final_df = df[['state_code', 'homeowner', 'group_size', 'car_age', 'car_value', 'risk_factor', 'age_oldest', 'age_youngest', 'married_couple', 'c_previous', 'duration_previous',\n",
        "              'A', 'E', 'F', 'cost']]\n",
        "final_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tHtJPF4CdX90"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Assuming `df` is your DataFrame with the relevant features\n",
        "X = final_df.drop('cost', axis=1)\n",
        "y = final_df['cost']\n",
        "\n",
        "# Perform the train-test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qOgAHa_XdX91"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Define the features to scale\n",
        "features_to_scale = ['car_age', 'age_oldest', 'age_youngest']\n",
        "\n",
        "# Create a scaler instance\n",
        "scaler = StandardScaler()\n",
        "\n",
        "# Fit the scaler on the training data and transform training data\n",
        "X_train_scaled = X_train.copy()\n",
        "X_train_scaled[features_to_scale] = scaler.fit_transform(X_train[features_to_scale])\n",
        "\n",
        "# Transform test data using the scaler fitted on training data\n",
        "X_test_scaled = X_test.copy()\n",
        "X_test_scaled[features_to_scale] = scaler.transform(X_test[features_to_scale])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VN42_mZydX92"
      },
      "outputs": [],
      "source": [
        "print(X_train_scaled.shape)\n",
        "print(X_test_scaled.shape)\n",
        "print(y_train.shape)\n",
        "print(y_test.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CE3eO1iddX93"
      },
      "outputs": [],
      "source": [
        "# Step 2: Choose a model and train it\n",
        "model = RandomForestRegressor(random_state=42)\n",
        "model.fit(X_train_scaled, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VcxclitCdX94"
      },
      "outputs": [],
      "source": [
        "# Step 3: Evaluate the model\n",
        "y_pred = model.predict(X_test_scaled)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7utQlQyidX95"
      },
      "outputs": [],
      "source": [
        "# Compute Mean Absolute Error (MAE)\n",
        "mae = mean_absolute_error(y_test, y_pred)\n",
        "\n",
        "# Compute R2 score (coefficient of determination)\n",
        "r2 = r2_score(y_test, y_pred)\n",
        "\n",
        "# Compute Mean Squared Error\n",
        "mse = mean_squared_error(y_test, y_pred)\n",
        "\n",
        "print(f\"Mean Absolute Error (MAE): {mae}\")\n",
        "print(f\"R-squared Score (R2): {r2}\")\n",
        "print(f\"Mean Squared Error: {mse}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4H_RbojofI2K"
      },
      "source": [
        "### *** Model Training 8 - Random Forest Regressor (14 features) AO-x, B-x - (0.875296)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zT3vQK0GfI2M"
      },
      "outputs": [],
      "source": [
        "final_df = df[['state_code', 'homeowner', 'group_size', 'car_age', 'car_value', 'risk_factor', 'age_youngest', 'married_couple', 'c_previous', 'duration_previous',\n",
        "              'A', 'E', 'F', 'G', 'cost']]\n",
        "final_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GGob0GnxfI2O"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Assuming `df` is your DataFrame with the relevant features\n",
        "X = final_df.drop('cost', axis=1)\n",
        "y = final_df['cost']\n",
        "\n",
        "# Perform the train-test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h_MUMSmyfI2O"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Define the features to scale\n",
        "features_to_scale = ['car_age', 'age_youngest']\n",
        "\n",
        "# Create a scaler instance\n",
        "scaler = StandardScaler()\n",
        "\n",
        "# Fit the scaler on the training data and transform training data\n",
        "X_train_scaled = X_train.copy()\n",
        "X_train_scaled[features_to_scale] = scaler.fit_transform(X_train[features_to_scale])\n",
        "\n",
        "# Transform test data using the scaler fitted on training data\n",
        "X_test_scaled = X_test.copy()\n",
        "X_test_scaled[features_to_scale] = scaler.transform(X_test[features_to_scale])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SG5kMlbUfI2P"
      },
      "outputs": [],
      "source": [
        "print(X_train_scaled.shape)\n",
        "print(X_test_scaled.shape)\n",
        "print(y_train.shape)\n",
        "print(y_test.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f0RmxvacfI2Q"
      },
      "outputs": [],
      "source": [
        "# Step 2: Choose a model and train it\n",
        "model = RandomForestRegressor(random_state=42)\n",
        "model.fit(X_train_scaled, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tZJPtmS5fI2R"
      },
      "outputs": [],
      "source": [
        "# Step 3: Evaluate the model\n",
        "y_pred = model.predict(X_test_scaled)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qgYJl20FfI2R"
      },
      "outputs": [],
      "source": [
        "# Compute Mean Absolute Error (MAE)\n",
        "mae = mean_absolute_error(y_test, y_pred)\n",
        "\n",
        "# Compute R2 score (coefficient of determination)\n",
        "r2 = r2_score(y_test, y_pred)\n",
        "\n",
        "# Compute Mean Squared Error\n",
        "mse = mean_squared_error(y_test, y_pred)\n",
        "\n",
        "print(f\"Mean Absolute Error (MAE): {mae}\")\n",
        "print(f\"R-squared Score (R2): {r2}\")\n",
        "print(f\"Mean Squared Error: {mse}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TV7EynO9ra1L"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YzAcr6K7ra-P"
      },
      "source": [
        "### *** Model Training 9 - Random Forest Regressor (16 features) D-y, AO-x, B-x - (0.8737)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KyIQrELtra-R"
      },
      "outputs": [],
      "source": [
        "final_df = df[['state_code', 'record_type', 'group_size', 'homeowner', 'car_age', 'car_value', 'risk_factor', 'age_youngest', 'married_couple',\n",
        "       'c_previous', 'duration_previous', 'A', 'D', 'E', 'F', 'G', 'cost']]\n",
        "final_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wmTw8wIjra-T"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Assuming `df` is your DataFrame with the relevant features\n",
        "X = final_df.drop('cost', axis=1)\n",
        "y = final_df['cost']\n",
        "\n",
        "# Perform the train-test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YHNGtX5yra-U"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Define the features to scale\n",
        "features_to_scale = ['car_age', 'age_youngest']\n",
        "\n",
        "# Create a scaler instance\n",
        "scaler = StandardScaler()\n",
        "\n",
        "# Fit the scaler on the training data and transform training data\n",
        "X_train_scaled = X_train.copy()\n",
        "X_train_scaled[features_to_scale] = scaler.fit_transform(X_train[features_to_scale])\n",
        "\n",
        "# Transform test data using the scaler fitted on training data\n",
        "X_test_scaled = X_test.copy()\n",
        "X_test_scaled[features_to_scale] = scaler.transform(X_test[features_to_scale])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WSoZx6Nkra-V"
      },
      "outputs": [],
      "source": [
        "print(X_train_scaled.shape)\n",
        "print(X_test_scaled.shape)\n",
        "print(y_train.shape)\n",
        "print(y_test.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rGiMczz_ra-X"
      },
      "outputs": [],
      "source": [
        "# Step 2: Choose a model and train it\n",
        "model = RandomForestRegressor(random_state=42)\n",
        "model.fit(X_train_scaled, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MXiSHDCjra-Y"
      },
      "outputs": [],
      "source": [
        "# Step 3: Evaluate the model\n",
        "y_pred = model.predict(X_test_scaled)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QsiXmR1ura-Z"
      },
      "outputs": [],
      "source": [
        "# Compute Mean Absolute Error (MAE)\n",
        "mae = mean_absolute_error(y_test, y_pred)\n",
        "\n",
        "# Compute R2 score (coefficient of determination)\n",
        "r2 = r2_score(y_test, y_pred)\n",
        "\n",
        "# Compute Mean Squared Error\n",
        "mse = mean_squared_error(y_test, y_pred)\n",
        "\n",
        "print(f\"Mean Absolute Error (MAE): {mae}\")\n",
        "print(f\"R-squared Score (R2): {r2}\")\n",
        "print(f\"Mean Squared Error: {mse}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SRavfqM_YZGN"
      },
      "source": [
        "### *** Model Training 10 - Random Forest Regressor (15 features) - (0.8737937)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K8I_7zqLYZGP"
      },
      "outputs": [],
      "source": [
        "final_df = df[['state_code', 'record_type', 'group_size', 'homeowner', 'car_age', 'car_value', 'risk_factor', 'age_youngest', 'married_couple',\n",
        "       'c_previous', 'duration_previous', 'A', 'E', 'F', 'G', 'cost']]\n",
        "final_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LIQqdWO-YZGQ"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Assuming `final_df` is your DataFrame with the relevant features and target 'cost'\n",
        "X = final_df.drop('cost', axis=1)\n",
        "y = final_df['cost']\n",
        "\n",
        "# Perform the train-test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EDakxvLfYZGS"
      },
      "outputs": [],
      "source": [
        "print(X_train.shape)\n",
        "print(X_test.shape)\n",
        "print(y_train.shape)\n",
        "print(y_test.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Czh9tlXYYZGT"
      },
      "outputs": [],
      "source": [
        "# Choose a model and train it\n",
        "best_model = RandomForestRegressor(n_estimators=120, random_state=42)\n",
        "best_model.fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5gp1FfzDYZGU"
      },
      "outputs": [],
      "source": [
        "# Predict on training and test sets\n",
        "y_train_pred = best_model.predict(X_train)\n",
        "y_test_pred = best_model.predict(X_test)\n",
        "\n",
        "# Compute Mean Absolute Error (MAE)\n",
        "train_mae = mean_absolute_error(y_train, y_train_pred)\n",
        "test_mae = mean_absolute_error(y_test, y_test_pred)\n",
        "\n",
        "# Compute R2 scores\n",
        "train_r2 = r2_score(y_train, y_train_pred)\n",
        "test_r2 = r2_score(y_test, y_test_pred)\n",
        "\n",
        "# Compute Mean Squared Error\n",
        "train_mse = mean_squared_error(y_train, y_train_pred)\n",
        "test_mse = mean_squared_error(y_test, y_test_pred)\n",
        "\n",
        "print(f\"Train MAE: {train_mae}\")\n",
        "print(f\"Test MAE: {test_mae}\")\n",
        "\n",
        "print(f\"\\nTrain R-squared Score: {train_r2}\")\n",
        "print(f\"Test R-squared Score: {test_r2}\")\n",
        "\n",
        "print(f\"\\nTrain MSE: {train_mse}\")\n",
        "print(f\"Test MSE: {test_mse}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dqd8foQUvcNe"
      },
      "source": [
        "### *** Model Training 11 - Random Forest Regressor (19 features) - (0.875317)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uZd_Q4CXvcNg"
      },
      "outputs": [],
      "source": [
        "final_df = df[['state_code', 'record_type', 'group_size', 'homeowner', 'car_age', 'car_value', 'risk_factor', 'age_oldest', 'age_youngest', 'married_couple',\n",
        "       'c_previous', 'duration_previous', 'A', 'B', 'C', 'D', 'E', 'F', 'G', 'cost']]\n",
        "final_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Cr18BCSdvcNj"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Assuming `final_df` is your DataFrame with the relevant features and target 'cost'\n",
        "X = final_df.drop('cost', axis=1)\n",
        "y = final_df['cost']\n",
        "\n",
        "# Perform the train-test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dEf9k7_MvcNk"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "# Define the features to scale\n",
        "features_to_scale = ['car_age', 'age_youngest']\n",
        "\n",
        "# Create a scaler instance\n",
        "scaler = MinMaxScaler()\n",
        "\n",
        "# Fit the scaler on the training data and transform training data\n",
        "X_train_scaled = X_train.copy()\n",
        "X_train_scaled[features_to_scale] = scaler.fit_transform(X_train[features_to_scale])\n",
        "\n",
        "# Transform test data using the scaler fitted on training data\n",
        "X_test_scaled = X_test.copy()\n",
        "X_test_scaled[features_to_scale] = scaler.transform(X_test[features_to_scale])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HVjiU93cvcNl"
      },
      "outputs": [],
      "source": [
        "print(X_train_scaled.shape)\n",
        "print(X_test_scaled.shape)\n",
        "print(y_train.shape)\n",
        "print(y_test.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w3wGXJnp_ZA-"
      },
      "outputs": [],
      "source": [
        "# Choose a model and train it\n",
        "best_model = RandomForestRegressor(n_estimators=120, random_state=42)\n",
        "best_model.fit(X_train_scaled, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vjkFxtr5vcNm"
      },
      "outputs": [],
      "source": [
        "# Predict on training and test sets\n",
        "y_train_pred = best_model.predict(X_train_scaled)\n",
        "y_test_pred = best_model.predict(X_test_scaled)\n",
        "\n",
        "# Compute Mean Absolute Error (MAE)\n",
        "train_mae = mean_absolute_error(y_train, y_train_pred)\n",
        "test_mae = mean_absolute_error(y_test, y_test_pred)\n",
        "\n",
        "# Compute R2 scores\n",
        "train_r2 = r2_score(y_train, y_train_pred)\n",
        "test_r2 = r2_score(y_test, y_test_pred)\n",
        "\n",
        "# Compute Mean Squared Error (MSE)\n",
        "train_mse = mean_squared_error(y_train, y_train_pred)\n",
        "test_mse = mean_squared_error(y_test, y_test_pred)\n",
        "\n",
        "print(f\"Train MAE: {train_mae}\")\n",
        "print(f\"Test MAE: {test_mae}\")\n",
        "\n",
        "print(f\"\\nTrain R-squared Score: {train_r2}\")\n",
        "print(f\"Test R-squared Score: {test_r2}\")\n",
        "\n",
        "print(f\"\\nTrain MSE: {train_mse}\")\n",
        "print(f\"Test MSE: {test_mse}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eWlGf6Mr9MEw"
      },
      "source": [
        "### Model Training 12 - XGBoost (16 features) X"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HHQOiiGk9ME1"
      },
      "outputs": [],
      "source": [
        "# final_df = df[['state_code', 'homeowner', 'group_size', 'car_age', 'car_value', 'risk_factor', 'age_oldest', 'age_youngest', 'married_couple', 'c_previous', 'duration_previous',\n",
        "#               'A', 'B', 'E', 'F', 'G', 'cost']]\n",
        "final_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4x8HNwoH9ME4"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Assuming `df` is your DataFrame with the relevant features\n",
        "X = final_df.drop('cost', axis=1)\n",
        "y = final_df['cost']\n",
        "\n",
        "# Perform the train-test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P4r9rDV-9ME6"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "# Define the features to scale\n",
        "features_to_scale = ['car_age', 'age_oldest', 'age_youngest']\n",
        "\n",
        "# Create a scaler instance\n",
        "scaler = MinMaxScaler()\n",
        "\n",
        "# Fit the scaler on the training data and transform training data\n",
        "X_train_scaled = X_train.copy()\n",
        "X_train_scaled[features_to_scale] = scaler.fit_transform(X_train[features_to_scale])\n",
        "\n",
        "# Transform test data using the scaler fitted on training data\n",
        "X_test_scaled = X_test.copy()\n",
        "X_test_scaled[features_to_scale] = scaler.transform(X_test[features_to_scale])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vA52XiwJ9ME8"
      },
      "outputs": [],
      "source": [
        "print(X_train_scaled.shape)\n",
        "print(X_test_scaled.shape)\n",
        "print(y_train.shape)\n",
        "print(y_test.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3v1zwiGM9ME_"
      },
      "outputs": [],
      "source": [
        "from xgboost import XGBRegressor\n",
        "\n",
        "xgb = XGBRegressor()\n",
        "xgb.fit(X_train_scaled, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hJ-sruL3_HeE"
      },
      "outputs": [],
      "source": [
        "y_pred_xgb = xgb.predict(X_test_scaled)\n",
        "\n",
        "mae_xgb = mean_absolute_error(y_test, y_pred_xgb)\n",
        "r2_xgb = r2_score(y_test, y_pred_xgb)\n",
        "mse_xgb = mean_squared_error(y_test, y_pred_xgb)\n",
        "\n",
        "print(\"XGBoost:\")\n",
        "print(f\"  Mean Absolute Error (MAE): {mae_xgb}\")\n",
        "print(f\"  R-squared Score (R2): {r2_xgb}\")\n",
        "print(f\"  Mean Squared Error: {mse_xgb}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "guHE_5Ql9nRk"
      },
      "source": [
        "### Model Training 13 - LightGBM (15 features) X"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6IHhE7Y79nRm"
      },
      "outputs": [],
      "source": [
        "final_df = df[['state_code', 'homeowner', 'group_size', 'car_age', 'car_value', 'risk_factor', 'age_oldest', 'age_youngest', 'married_couple', 'c_previous', 'duration_previous',\n",
        "              'A', 'B', 'E', 'F', 'G', 'cost']]\n",
        "final_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Mn2DiFM89nRn"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Assuming `df` is your DataFrame with the relevant features\n",
        "X = final_df.drop('cost', axis=1)\n",
        "y = final_df['cost']\n",
        "\n",
        "# Perform the train-test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JRhywMFS9nRn"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Define the features to scale\n",
        "features_to_scale = ['car_age', 'age_oldest', 'age_youngest']\n",
        "\n",
        "# Create a scaler instance\n",
        "scaler = StandardScaler()\n",
        "\n",
        "# Fit the scaler on the training data and transform training data\n",
        "X_train_scaled = X_train.copy()\n",
        "X_train_scaled[features_to_scale] = scaler.fit_transform(X_train[features_to_scale])\n",
        "\n",
        "# Transform test data using the scaler fitted on training data\n",
        "X_test_scaled = X_test.copy()\n",
        "X_test_scaled[features_to_scale] = scaler.transform(X_test[features_to_scale])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fo0WvtmL9nRo"
      },
      "outputs": [],
      "source": [
        "print(X_train_scaled.shape)\n",
        "print(X_test_scaled.shape)\n",
        "print(y_train.shape)\n",
        "print(y_test.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A5hEeeZ29nRp"
      },
      "outputs": [],
      "source": [
        "import lightgbm as lgb\n",
        "\n",
        "lgbm = lgb.LGBMRegressor()\n",
        "lgbm.fit(X_train_scaled, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JJfhux9__MQu"
      },
      "outputs": [],
      "source": [
        "y_pred_lgbm = lgbm.predict(X_test_scaled)\n",
        "\n",
        "mae_lgbm = mean_absolute_error(y_test, y_pred_lgbm)\n",
        "r2_lgbm = r2_score(y_test, y_pred_lgbm)\n",
        "mse_lgbm = mean_squared_error(y_test, y_pred_lgbm)\n",
        "\n",
        "print(\"LightGBM:\")\n",
        "print(f\"  Mean Absolute Error (MAE): {mae_lgbm}\")\n",
        "print(f\"  R-squared Score (R2): {r2_lgbm}\")\n",
        "print(f\"  Mean Squared Error: {mse_lgbm}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1Y_iLfI59_bJ"
      },
      "source": [
        "### Model Training 14 - CatBoost (15 features) X"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BU-AFI-E9_bL"
      },
      "outputs": [],
      "source": [
        "final_df = df[['state_code', 'homeowner', 'group_size', 'car_age', 'car_value', 'risk_factor', 'age_oldest', 'age_youngest', 'married_couple', 'c_previous', 'duration_previous',\n",
        "              'A', 'B', 'E', 'F', 'G', 'cost']]\n",
        "final_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N6glT0N-9_bN"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Assuming `df` is your DataFrame with the relevant features\n",
        "X = final_df.drop('cost', axis=1)\n",
        "y = final_df['cost']\n",
        "\n",
        "# Perform the train-test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jiTka87-9_bP"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Define the features to scale\n",
        "features_to_scale = ['car_age', 'age_oldest', 'age_youngest']\n",
        "\n",
        "# Create a scaler instance\n",
        "scaler = StandardScaler()\n",
        "\n",
        "# Fit the scaler on the training data and transform training data\n",
        "X_train_scaled = X_train.copy()\n",
        "X_train_scaled[features_to_scale] = scaler.fit_transform(X_train[features_to_scale])\n",
        "\n",
        "# Transform test data using the scaler fitted on training data\n",
        "X_test_scaled = X_test.copy()\n",
        "X_test_scaled[features_to_scale] = scaler.transform(X_test[features_to_scale])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-VKOHqJ-9_bP"
      },
      "outputs": [],
      "source": [
        "print(X_train_scaled.shape)\n",
        "print(X_test_scaled.shape)\n",
        "print(y_train.shape)\n",
        "print(y_test.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "04PJVMJX9_bQ"
      },
      "outputs": [],
      "source": [
        "from catboost import CatBoostRegressor\n",
        "\n",
        "catboost = CatBoostRegressor(verbose=0)\n",
        "catboost.fit(X_train_scaled, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "juMbFzOS_QBX"
      },
      "outputs": [],
      "source": [
        "y_pred_catboost = catboost.predict(X_test_scaled)\n",
        "\n",
        "mae_catboost = mean_absolute_error(y_test, y_pred_catboost)\n",
        "r2_catboost = r2_score(y_test, y_pred_catboost)\n",
        "mse_catboost = mean_squared_error(y_test, y_pred_catboost)\n",
        "\n",
        "print(\"CatBoost:\")\n",
        "print(f\"  Mean Absolute Error (MAE): {mae_catboost}\")\n",
        "print(f\"  R-squared Score (R2): {r2_catboost}\")\n",
        "print(f\"  Mean Squared Error: {mse_catboost}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ergoEgdQQFJZ"
      },
      "source": [
        "### Model Training 15 - RFR, LR, KNR, GBR, MLPR (14 features) X\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_9vsWrnrQFJa"
      },
      "outputs": [],
      "source": [
        "final_df = df[['state_code', 'homeowner', 'group_size', 'car_age', 'car_value', 'risk_factor', 'age_oldest', 'age_youngest', 'married_couple', 'c_previous', 'duration_previous',\n",
        "              'A', 'B', 'E', 'F', 'G', 'cost']]\n",
        "final_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Bv2ZRuGpQFJc"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Assuming `df` is your DataFrame with the relevant features\n",
        "X = final_df.drop('cost', axis=1)\n",
        "y = final_df['cost']\n",
        "\n",
        "# Perform the train-test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EnZlqYmhQFJd"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Define the features to scale\n",
        "features_to_scale = ['car_age', 'age_oldest', 'age_youngest']\n",
        "\n",
        "# Create a scaler instance\n",
        "scaler = StandardScaler()\n",
        "\n",
        "# Fit the scaler on the training data and transform training data\n",
        "X_train_scaled = X_train.copy()\n",
        "X_train_scaled[features_to_scale] = scaler.fit_transform(X_train[features_to_scale])\n",
        "\n",
        "# Transform test data using the scaler fitted on training data\n",
        "X_test_scaled = X_test.copy()\n",
        "X_test_scaled[features_to_scale] = scaler.transform(X_test[features_to_scale])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mgQUflRiQFJe"
      },
      "outputs": [],
      "source": [
        "print(X_train_scaled.shape)\n",
        "print(X_test_scaled.shape)\n",
        "print(y_train.shape)\n",
        "print(y_test.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-bTLNHjLQFJf"
      },
      "outputs": [],
      "source": [
        "# Example usage of different regressors\n",
        "models = {\n",
        "    'Decision Trees': DecisionTreeRegressor(),\n",
        "    'Linear Regression': LinearRegression(),\n",
        "    'K-Nearest Neighbors': KNeighborsRegressor(),\n",
        "    'Gradient Boosting': GradientBoostingRegressor()\n",
        "}\n",
        "\n",
        "# Iterate over models and fit/evaluate as needed\n",
        "for name, model in models.items():\n",
        "    model.fit(X_train_scaled, y_train)\n",
        "    y_pred = model.predict(X_test_scaled)\n",
        "    mae = mean_absolute_error(y_test, y_pred)\n",
        "    r2 = r2_score(y_test, y_pred)\n",
        "    print(f\"Model: {name}\")\n",
        "    print(f\"  Mean Absolute Error (MAE): {mae}\")\n",
        "    print(f\"  R-squared Score (R2): {r2}\")\n",
        "    print()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "al8v3jZ1Ff3y"
      },
      "source": [
        "### Model Training 16 - Hyperparameter Tuning on Random Forest Regressor (15 features)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lwYLgk2IFf30"
      },
      "outputs": [],
      "source": [
        "final_df = df[['state_code', 'record_type', 'group_size', 'homeowner', 'car_age', 'car_value', 'risk_factor', 'age_youngest', 'married_couple',\n",
        "       'c_previous', 'duration_previous', 'A', 'E', 'F', 'G', 'cost']]\n",
        "final_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qD8XroSaFf31"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Assuming `df` is your DataFrame with the relevant features\n",
        "X = final_df.drop('cost', axis=1)\n",
        "y = final_df['cost']\n",
        "\n",
        "# Perform the train-test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "35CsOC45Ff33"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "# Define the features to scale\n",
        "features_to_scale = ['car_age', 'age_youngest']\n",
        "\n",
        "# Create a scaler instance\n",
        "scaler = MinMaxScaler()\n",
        "\n",
        "# Fit the scaler on the training data and transform training data\n",
        "X_train_scaled = X_train.copy()\n",
        "X_train_scaled[features_to_scale] = scaler.fit_transform(X_train[features_to_scale])\n",
        "\n",
        "# Transform test data using the scaler fitted on training data\n",
        "X_test_scaled = X_test.copy()\n",
        "X_test_scaled[features_to_scale] = scaler.transform(X_test[features_to_scale])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PyzjRDPfFf36"
      },
      "outputs": [],
      "source": [
        "print(X_train_scaled.shape)\n",
        "print(X_test_scaled.shape)\n",
        "print(y_train.shape)\n",
        "print(y_test.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LNiqa4yHGW9L"
      },
      "outputs": [],
      "source": [
        "import time\n",
        "\n",
        "param_grid = {\n",
        "    'n_estimators': [50, 100, 120],\n",
        "    'max_features': ['sqrt', 'log2'],\n",
        "    'max_depth': [8, None],\n",
        "    'min_samples_split': [5, 8],\n",
        "    'min_samples_leaf': [1, 4]\n",
        "}\n",
        "\n",
        "rf = RandomForestRegressor(random_state=42)\n",
        "grid_search = GridSearchCV(estimator=rf, param_grid=param_grid, cv=3, n_jobs=-1, verbose=3)\n",
        "\n",
        "start_time = time.time()\n",
        "grid_search.fit(X_train_scaled, y_train)\n",
        "end_time = time.time()\n",
        "\n",
        "elapsed_time = end_time - start_time\n",
        "print(f\"Grid search completed in {elapsed_time // 60} minutes and {elapsed_time % 60} seconds\")\n",
        "\n",
        "best_params = grid_search.best_params_\n",
        "best_model = grid_search.best_estimator_\n",
        "\n",
        "print(\"Best Parameters:\", best_params)\n",
        "print(\"Best Model:\", best_model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bAzE7RN1GoXe"
      },
      "outputs": [],
      "source": [
        "# Predict on training and test sets\n",
        "y_train_pred = best_model.predict(X_train_scaled)\n",
        "y_test_pred = best_model.predict(X_test_scaled)\n",
        "\n",
        "# Compute Mean Absolute Error (MAE)\n",
        "train_mae = mean_absolute_error(y_train, y_train_pred)\n",
        "test_mae = mean_absolute_error(y_test, y_test_pred)\n",
        "\n",
        "# Compute R2 scores\n",
        "train_r2 = r2_score(y_train, y_train_pred)\n",
        "test_r2 = r2_score(y_test, y_test_pred)\n",
        "\n",
        "# Compute Mean Squared Error\n",
        "train_mse = mean_squared_error(y_train, y_train_pred)\n",
        "test_mse = mean_squared_error(y_test, y_test_pred)\n",
        "\n",
        "print(f\"Train MAE: {train_mae}\")\n",
        "print(f\"Test MAE: {test_mae}\")\n",
        "\n",
        "print(f\"\\nTrain R-squared Score: {train_r2}\")\n",
        "print(f\"Test R-squared Score: {test_r2}\")\n",
        "\n",
        "print(f\"\\nTrain MSE: {train_mse}\")\n",
        "print(f\"Test MSE: {test_mse}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ze0TS7S_y1dL",
        "outputId": "03764213-9564-4f31-9dfc-6db028a40e17"
      },
      "outputs": [],
      "source": [
        "model = joblib.load('model.joblib')\n",
        "if hasattr(model, '__version__'):\n",
        "    print(f\"Version of the loaded object: {model.__version__}\")\n",
        "else:\n",
        "    print(\"No version information found.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NlQdXIp5y6mm"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "vXAHrJ0LCNO7",
        "zrSGFFG5qzhS",
        "6R5k-a8KqsnU",
        "tE6XJ8SloNk4",
        "5LQ7e-SIpfq_",
        "d7gD1JOxG-2G",
        "C0LsnkCerHQN",
        "4q7YpM_Ubxcn",
        "43_ioRLgmPbi",
        "cZsaRjcGmVLg",
        "DEe1wYi4BCPV",
        "5yx86oZqBit1",
        "EWSUV4tsmoII",
        "qrvSIaKyFi4W",
        "0xTw4b5EruyT",
        "nFig3WgiAfg7",
        "rE-RTZuiAmsy",
        "MBqWuZAzBPeC",
        "gxiW33RDCZo9",
        "3LVrb7VnUGUX",
        "lMenekuQGDEF",
        "mJCbZmA9dX9w",
        "4H_RbojofI2K",
        "YzAcr6K7ra-P",
        "SRavfqM_YZGN",
        "dqd8foQUvcNe",
        "guHE_5Ql9nRk",
        "1Y_iLfI59_bJ",
        "ergoEgdQQFJZ",
        "al8v3jZ1Ff3y",
        "JfGgyuV2V8Q6"
      ],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
